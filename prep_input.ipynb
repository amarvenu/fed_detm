{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fa91bd-8bba-4be7-b60d-a20505e719f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/amarvenu/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer, T5Model, T5Tokenizer\n",
    "import torch\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3f6db5-e3a1-4ef5-a734-d2348dc0fa02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/combined_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b276ea7c-b599-41d0-bd23-bb44b5f763b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_vec = CountVectorizer(min_df=0.01, max_df=0.9).fit(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21e7b52-c1f7-4d7e-9aff-1823bc61dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down the documents, filtered for words in the cv list\n",
    "def filter_text(text):\n",
    "    return ' '.join([x for x in text.split() if x in filter_vec.vocabulary_])\n",
    "\n",
    "df['filtered_text'] = df['clean_text'].apply(filter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1226dcbd-ecb1-4f55-bf65-da50104a7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit(df['filtered_text'])\n",
    "counts = vectorizer.transform(df['clean_text'])\n",
    "counts.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ed8330-329d-4750-b58b-53b426d3ae19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1650it [00:00, 4039.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokens = []\n",
    "train_counts = []\n",
    "for c in tqdm(counts):\n",
    "    train_tokens.append(np.nonzero(c)[1])\n",
    "    train_counts.append(np.squeeze(np.array(c[c > 0])))\n",
    "    \n",
    "train_tokens = np.array(train_tokens, dtype='object')\n",
    "train_counts = np.array(train_counts, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed009d10-7c6e-4813-82f8-35fc5827bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['date'] <= '2006-01-31', 'slice'] = 0  # Greenspan\n",
    "df.loc[('2006-02-01' <= df['date']) & (df['date'] <= '2014-01-31'), 'slice'] = 1  # Bernanke\n",
    "df.loc[('2014-02-03' <= df['date']) & (df['date'] < '2018-02-03'), 'slice'] = 2  # Yellen\n",
    "df.loc['2018-02-05' <= df['date'], 'slice'] = 3  # Powell\n",
    "\n",
    "df['slice'] = df['slice'].astype(int)\n",
    "\n",
    "train_times = df['slice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e22e4e3-4791-4f2a-88f6-6c2af097ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data/combined_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24bd784d-0bdf-4434-8d76-d646c2c6b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice\n",
       "0    716\n",
       "1    546\n",
       "2    201\n",
       "3    187\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('slice').date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9b530-bc10-42fc-a97d-06caa8722d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1e2c4-9663-42d1-870a-6b59423c6ff3",
   "metadata": {},
   "source": [
    "## prep embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd93596-150b-4030-934c-f66c488402bd",
   "metadata": {},
   "source": [
    "### bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7998151d-4233-494c-bc48-b9ad3302a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec(word, tokenizer, embeddings):\n",
    "    input_ids = torch.tensor(tokenizer.encode(word, add_special_tokens=False))\n",
    "    return embeddings(input_ids).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d7516158-df13-41cc-ab9f-90ede82219ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eac90293-11f0-4c69-b086-aee3236ffb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4938/4938 [00:00<00:00, 5156.63it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((len(vocab), 768))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    embeddings[idx] = get_word_vec(w, tokenizer, model.embeddings.word_embeddings).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef6027e7-0359-41f3-bdf4-ac7e462e4ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings.sum(axis=1) == 0).max()  # check that all were filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "79239336-a140-4602-a31f-9958fb1046a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=np.array(vocab),\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "92c8c91b-c0d3-45f2-88ba-216cdaf91f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "berttokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bertmodel = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "24386f2e-33df-4708-a9d1-46a4ed33316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = bertmodel(torch.tensor(berttokenizer.encode('hello')).unsqueeze(0))\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b931ebc2-cecc-4d15-b361-33d4f95a051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.mean(axis=1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c128ea02-eb3f-4268-a12d-877f5412f781",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 49/4938 [00:24<40:56,  1.99it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tqdm(vocab):\n\u001b[1;32m      4\u001b[0m     idx \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mvocabulary_[w]\n\u001b[0;32m----> 5\u001b[0m     embeddings[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mbertmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mberttokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1012\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1013\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1014\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[0;32m-> 1019\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:464\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    462\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    463\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 464\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((len(vocab), 768))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    embeddings[idx] = bertmodel(torch.tensor(berttokenizer.encode(w)).unsqueeze(0)).last_hidden_state.mean(axis=1).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c96d7-d6e9-43a0-a937-341a7dbe6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data_bert_alt.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=np.array(vocab),\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2b19a-a247-4df5-a8d1-856bda72ac9b",
   "metadata": {},
   "source": [
    "### glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed71adbc-84f5-4412-9e73-b75b9c6f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "orig = np.load('test_data.npz', allow_pickle=True)\n",
    "train_tokens=orig['train_tokens']\n",
    "train_counts=orig['train_counts']\n",
    "train_times=orig['train_times']\n",
    "vocab=orig['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93472f96-6e15-4ed6-8838-970d44fe7a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:09<00:00, 40875.09it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = dict()\n",
    "with open('embeddings/glove.6B.300d.txt') as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        w = line.split()[0].strip()\n",
    "        if w in vocab:\n",
    "            glove_embeddings[w] = np.array([float(x) for x in line.split()[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba55627b-3be3-4868-a0a3-a4775a65845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4938/4938 [00:00<00:00, 307437.85it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((len(vocab), glove_embeddings['economy'].shape[0]))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    if w in glove_embeddings:\n",
    "        embeddings[idx] = glove_embeddings[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1ce83f-5d5e-4751-bccb-2494f9e55630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4938, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d427f9-c9d3-4897-96fb-bf4646f997a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data_glove.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=vocab,\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28821c02-668a-4ad0-a1f0-56ac38c50a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "tmp = np.load(\n",
    "    'test_data_glove.npz'\n",
    ")['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd762a27-7956-48e7-ba03-fded46ce45fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474901e2-3fea-4c64-89b7-e7bfe3b136dc",
   "metadata": {},
   "source": [
    "### t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6913b005-b4a8-48b5-a5d6-8f0a8e717ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "orig = np.load('test_data.npz', allow_pickle=True)\n",
    "train_tokens=orig['train_tokens']\n",
    "train_counts=orig['train_counts']\n",
    "train_times=orig['train_times']\n",
    "vocab=orig['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692843ef-750a-45c3-b4e2-c131955335e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/amarvenu/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5Model.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4331946a-4585-4e45-866c-cf0487b9eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t5_word_vec(word, tokenizer, model):\n",
    "    tok = tokenizer(word, return_tensors='pt', add_special_tokens=False)\n",
    "    emb = model.encoder(\n",
    "        input_ids=tok['input_ids'],\n",
    "        attention_mask=tok['attention_mask'],\n",
    "        return_dict=True\n",
    "    )\n",
    "    \n",
    "    return emb.last_hidden_state.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd3c89af-ebb0-4832-a877-4d2e55ca70b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4938/4938 [10:32<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((len(vocab), 768))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    embeddings[idx] = get_t5_word_vec(w, tokenizer, model).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "191c990b-4a6f-462f-b4e6-c2a3bacd8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings.sum(axis=1) == 0).max()  # check that all were filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bcc1c6f-8422-4872-baea-c40922b84757",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data_t5.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=vocab,\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea0087c9-1961-4e43-a7e9-9f6c1b2bc95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "473fc348-8e82-4699-b3c9-614f132e89fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1429,  0.2725, -0.0193,  0.2019, -0.0759,  0.4104,  0.0384, -0.2304,\n",
       "        -0.2852, -0.3313], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = tokenizer('hello', return_tensors='pt', add_special_tokens=False)\n",
    "emb = model.encoder(\n",
    "    input_ids=tok['input_ids'],\n",
    "    attention_mask=tok['attention_mask'],\n",
    "    return_dict=True\n",
    ")\n",
    "emb.last_hidden_state.mean(axis=1).squeeze()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01ac9305-8b37-4550-a448-a95b6b6b96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t5_word_vec_alt(word, tokenizer, model):\n",
    "    tok = tokenizer(word, return_tensors='pt', add_special_tokens=False)\n",
    "    return model.encoder.embed_tokens(tok['input_ids']).mean(axis=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2fd578b9-c8ca-4d0d-9409-44201016c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4938/4938 [00:00<00:00, 6422.10it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_alt = np.zeros((len(vocab), 768))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    embeddings_alt[idx] = get_t5_word_vec_alt(w, tokenizer, model).squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b42fd0aa-5009-479f-bda9-7714c1972025",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data_t5_alt.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=vocab,\n",
    "    embeddings=embeddings_alt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "86629d9f-5d6f-4015-a10d-c3f2ce4dad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t5_word_vec_pooled(word, tokenizer, model):\n",
    "    tok = tokenizer('hello', return_tensors='pt', add_special_tokens=False)\n",
    "    emb = model.encoder(\n",
    "        input_ids=tok['input_ids'],\n",
    "        attention_mask=tok['attention_mask'],\n",
    "        return_dict=True,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    \n",
    "    return torch.stack(emb.hidden_states).mean(axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "491c3ca0-8263-449e-8366-36e094b1a020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4938/4938 [06:41<00:00, 12.30it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_pooled = np.zeros((len(vocab), 768))\n",
    "\n",
    "for w in tqdm(vocab):\n",
    "    idx = vectorizer.vocabulary_[w]\n",
    "    embeddings_pooled[idx] = get_t5_word_vec_pooled(w, tokenizer, model).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4193c076-cf3f-4954-a080-00697bef6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save down everything\n",
    "np.savez_compressed(\n",
    "    'test_data_t5_pooled.npz', \n",
    "    train_tokens=train_tokens,\n",
    "    train_counts=train_counts,\n",
    "    train_times=train_times,\n",
    "    vocab=vocab,\n",
    "    embeddings=embeddings_pooled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d55b4-0130-4e3c-805f-234f1320cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
