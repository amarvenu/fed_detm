{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b842b476-674e-4f7c-97ff-6573850ba701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/amarvenu/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from run import get_args, process_data, prep_files, get_model, train\n",
    "import torch\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm\n",
    "from analysis_utils import get_detm_topics, topic_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098ca3c1-40e0-4d72-a367-bce9f749b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data and file related arguments\n",
    "arg_str = \"\"\"\n",
    "parser.add_argument('--dataset', type=str, default='un', help='name of corpus')\n",
    "parser.add_argument('--data_path', type=str, default='un/', help='directory containing data')\n",
    "parser.add_argument('--emb_path', type=str, default='skipgram/embeddings.txt', help='directory containing embeddings')\n",
    "parser.add_argument('--save_path', type=str, default='./results', help='path to save results')\n",
    "parser.add_argument('--batch_size', type=int, default=1000, help='number of documents in a batch for training')\n",
    "parser.add_argument('--min_df', type=int, default=100, help='to get the right data..minimum document frequency')\n",
    "\n",
    "### model-related arguments\n",
    "parser.add_argument('--num_topics', type=int, default=50, help='number of topics')\n",
    "parser.add_argument('--rho_size', type=int, default=300, help='dimension of rho')\n",
    "parser.add_argument('--emb_size', type=int, default=300, help='dimension of embeddings')\n",
    "parser.add_argument('--t_hidden_size', type=int, default=800, help='dimension of hidden space of q(theta)')\n",
    "parser.add_argument('--theta_act', type=str, default='relu', help='tanh, softplus, relu, rrelu, leakyrelu, elu, selu, glu)')\n",
    "parser.add_argument('--train_embeddings', type=int, default=1, help='whether to fix rho or train it')\n",
    "parser.add_argument('--eta_nlayers', type=int, default=3, help='number of layers for eta')\n",
    "parser.add_argument('--eta_hidden_size', type=int, default=200, help='number of hidden units for rnn')\n",
    "parser.add_argument('--delta', type=float, default=0.005, help='prior variance')\n",
    "\n",
    "### optimization-related arguments\n",
    "parser.add_argument('--lr', type=float, default=0.005, help='learning rate')\n",
    "parser.add_argument('--lr_factor', type=float, default=4.0, help='divide learning rate by this')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train')\n",
    "parser.add_argument('--mode', type=str, default='train', help='train or eval model')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='choice of optimizer')\n",
    "parser.add_argument('--seed', type=int, default=2019, help='random seed (default: 1)')\n",
    "parser.add_argument('--enc_drop', type=float, default=0.0, help='dropout rate on encoder')\n",
    "parser.add_argument('--eta_dropout', type=float, default=0.0, help='dropout rate on rnn for eta')\n",
    "parser.add_argument('--clip', type=float, default=0.0, help='gradient clipping')\n",
    "parser.add_argument('--nonmono', type=int, default=10, help='number of bad hits allowed')\n",
    "parser.add_argument('--wdecay', type=float, default=1.2e-6, help='some l2 regularization')\n",
    "parser.add_argument('--anneal_lr', type=int, default=0, help='whether to anneal the learning rate or not')\n",
    "parser.add_argument('--bow_norm', type=int, default=1, help='normalize the bows or not')\n",
    "\n",
    "### evaluation, visualization, and logging-related arguments\n",
    "parser.add_argument('--num_words', type=int, default=20, help='number of words for topic viz')\n",
    "parser.add_argument('--log_interval', type=int, default=10, help='when to log training')\n",
    "parser.add_argument('--visualize_every', type=int, default=1, help='when to visualize results')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=1000, help='input batch size for evaluation')\n",
    "parser.add_argument('--load_from', type=str, default='', help='the name of the ckpt to eval from')\n",
    "parser.add_argument('--tc', type=int, default=0, help='whether to compute tc or not')\n",
    "\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbb0cf6-cb59-4c14-9d3f-7425c4cef152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495f46a1-bb2a-45a3-94e2-8e33eda49897",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [x.strip(\"parser.add_argument('\").split(',')[0].strip('--').strip(\"'\") for x in arg_str if (len(x) > 0) and (not x.startswith('#'))]\n",
    "values = [x.strip(\"parser.add_argument('\").split(',')[2].strip(\" default=\").strip(\"'\") for x in arg_str if (len(x) > 0) and (not x.startswith('#'))]\n",
    "tmp_dict = dict(zip(keys, values))\n",
    "\n",
    "for k, v in tmp_dict.items():\n",
    "    if v.isnumeric():\n",
    "        tmp_dict[k] = int(v)\n",
    "    elif ('.' in v) and (v[0].isnumeric()):\n",
    "        tmp_dict[k] = float(v)    \n",
    "\n",
    "args = AttrDict()\n",
    "args.update(tmp_dict)\n",
    "\n",
    "args.train_embeddings = 0\n",
    "args.num_topics = 10\n",
    "args.batch_size = 100\n",
    "args.epochs = 150\n",
    "args.num_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5be51b-033c-4fc4-966f-fd47d89439a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0/2\n"
     ]
    }
   ],
   "source": [
    "train_rnn_inp, train_tokens, train_counts, train_times, vocab, embeddings, args = process_data(\n",
    "    file='test_data_t5_alt.npz',\n",
    "    args=args\n",
    ")\n",
    "\n",
    "args.rho_size = embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e5a96e-0d0b-4ca3-8a36-e281c320caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = prep_files(args, 't5_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d57391-ae53-4c16-ad59-2687f61dd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, args = get_model(args, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46ab345-d734-48d4-b63b-116e9514f638",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3572.63 .. KL_eta: 2086.58 .. KL_alpha: 11731760.45 .. Rec_loss: 31495962.73 .. NELBO: 43233383.64\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 2447.51 .. KL_eta: 1368.06 .. KL_alpha: 11552055.12 .. Rec_loss: 31966265.06 .. NELBO: 43522137.18\n",
      "****************************************************************************************************\n",
      "Epoch: 2 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 207.31 .. KL_eta: 58.31 .. KL_alpha: 10764409.73 .. Rec_loss: 31897463.64 .. NELBO: 42662140.36\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 168.13 .. KL_eta: 60.33 .. KL_alpha: 10608247.29 .. Rec_loss: 32000478.12 .. NELBO: 42608954.82\n",
      "****************************************************************************************************\n",
      "Epoch: 3 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 113.59 .. KL_eta: 66.15 .. KL_alpha: 9892885.82 .. Rec_loss: 31533744.0 .. NELBO: 41426808.73\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 93.96 .. KL_eta: 65.79 .. KL_alpha: 9766931.0 .. Rec_loss: 32024218.12 .. NELBO: 41791308.47\n",
      "****************************************************************************************************\n",
      "Epoch: 4 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 135.13 .. KL_eta: 63.53 .. KL_alpha: 9117332.82 .. Rec_loss: 31793596.0 .. NELBO: 40911129.09\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 147.45 .. KL_eta: 62.64 .. KL_alpha: 8994999.0 .. Rec_loss: 31948409.41 .. NELBO: 40943619.76\n",
      "****************************************************************************************************\n",
      "Epoch: 5 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 188.49 .. KL_eta: 59.77 .. KL_alpha: 8504291.68 .. Rec_loss: 31894011.45 .. NELBO: 40398551.64\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 167.2 .. KL_eta: 58.72 .. KL_alpha: 8403747.41 .. Rec_loss: 32015203.76 .. NELBO: 40419177.18\n",
      "****************************************************************************************************\n",
      "Epoch: 6 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 132.85 .. KL_eta: 53.92 .. KL_alpha: 7912434.18 .. Rec_loss: 31710959.27 .. NELBO: 39623580.36\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 154.07 .. KL_eta: 54.09 .. KL_alpha: 7820367.15 .. Rec_loss: 31943455.06 .. NELBO: 39764030.82\n",
      "****************************************************************************************************\n",
      "Epoch: 7 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 278.89 .. KL_eta: 51.68 .. KL_alpha: 7459897.23 .. Rec_loss: 31443325.27 .. NELBO: 38903553.09\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 240.04 .. KL_eta: 51.53 .. KL_alpha: 7367631.44 .. Rec_loss: 32021760.12 .. NELBO: 39389683.06\n",
      "****************************************************************************************************\n",
      "Epoch: 8 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 109.23 .. KL_eta: 48.2 .. KL_alpha: 7055970.05 .. Rec_loss: 31958160.73 .. NELBO: 39014288.36\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 121.22 .. KL_eta: 47.83 .. KL_alpha: 6973371.0 .. Rec_loss: 32060538.47 .. NELBO: 39034078.59\n",
      "****************************************************************************************************\n",
      "Epoch: 9 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 156.53 .. KL_eta: 46.08 .. KL_alpha: 6647277.18 .. Rec_loss: 31588154.91 .. NELBO: 38235633.82\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 163.35 .. KL_eta: 46.34 .. KL_alpha: 6583535.94 .. Rec_loss: 32055866.35 .. NELBO: 38639611.53\n",
      "****************************************************************************************************\n",
      "Epoch: 10 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 174.55 .. KL_eta: 46.24 .. KL_alpha: 6300603.82 .. Rec_loss: 31644529.64 .. NELBO: 37945354.91\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 198.22 .. KL_eta: 46.84 .. KL_alpha: 6251105.88 .. Rec_loss: 32024575.29 .. NELBO: 38275926.82\n",
      "****************************************************************************************************\n",
      "Epoch: 11 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 226.58 .. KL_eta: 46.99 .. KL_alpha: 6003247.64 .. Rec_loss: 32608704.18 .. NELBO: 38612226.18\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 215.26 .. KL_eta: 47.8 .. KL_alpha: 5966019.38 .. Rec_loss: 31886910.24 .. NELBO: 37853193.18\n",
      "****************************************************************************************************\n",
      "Epoch: 12 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 150.43 .. KL_eta: 48.31 .. KL_alpha: 5756145.64 .. Rec_loss: 31501558.18 .. NELBO: 37257902.91\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 142.93 .. KL_eta: 49.09 .. KL_alpha: 5703001.26 .. Rec_loss: 32029086.82 .. NELBO: 37732280.24\n",
      "****************************************************************************************************\n",
      "Epoch: 13 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 215.31 .. KL_eta: 49.58 .. KL_alpha: 5469926.91 .. Rec_loss: 31814442.18 .. NELBO: 37284633.82\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 193.21 .. KL_eta: 48.9 .. KL_alpha: 5438478.09 .. Rec_loss: 31979478.47 .. NELBO: 37418198.82\n",
      "****************************************************************************************************\n",
      "Epoch: 14 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 128.04 .. KL_eta: 48.0 .. KL_alpha: 5277174.45 .. Rec_loss: 31739620.0 .. NELBO: 37016971.27\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 141.74 .. KL_eta: 48.03 .. KL_alpha: 5240774.35 .. Rec_loss: 31973561.41 .. NELBO: 37214525.41\n",
      "****************************************************************************************************\n",
      "Epoch: 15 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 287.96 .. KL_eta: 47.47 .. KL_alpha: 5072554.59 .. Rec_loss: 32657868.55 .. NELBO: 37730758.55\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 280.03 .. KL_eta: 48.1 .. KL_alpha: 5031404.32 .. Rec_loss: 31826152.94 .. NELBO: 36857884.71\n",
      "****************************************************************************************************\n",
      "Epoch: 16 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 306.48 .. KL_eta: 47.75 .. KL_alpha: 4862429.05 .. Rec_loss: 32176626.91 .. NELBO: 37039410.55\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 332.54 .. KL_eta: 47.78 .. KL_alpha: 4835973.85 .. Rec_loss: 31897511.29 .. NELBO: 36733866.12\n",
      "****************************************************************************************************\n",
      "Epoch: 17 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 257.84 .. KL_eta: 48.43 .. KL_alpha: 4676555.05 .. Rec_loss: 32121712.73 .. NELBO: 36798573.82\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 256.95 .. KL_eta: 47.68 .. KL_alpha: 4640489.18 .. Rec_loss: 31919347.41 .. NELBO: 36560141.18\n",
      "****************************************************************************************************\n",
      "Epoch: 18 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 384.07 .. KL_eta: 47.89 .. KL_alpha: 4505588.68 .. Rec_loss: 32252485.64 .. NELBO: 36758505.82\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 319.3 .. KL_eta: 48.24 .. KL_alpha: 4484914.21 .. Rec_loss: 31934955.53 .. NELBO: 36420236.82\n",
      "****************************************************************************************************\n",
      "Epoch: 19 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 238.13 .. KL_eta: 48.46 .. KL_alpha: 4354740.23 .. Rec_loss: 31554243.82 .. NELBO: 35909270.91\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 277.9 .. KL_eta: 48.04 .. KL_alpha: 4330732.85 .. Rec_loss: 31921912.71 .. NELBO: 36252971.53\n",
      "****************************************************************************************************\n",
      "Epoch: 20 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 367.36 .. KL_eta: 48.31 .. KL_alpha: 4202635.18 .. Rec_loss: 31747470.73 .. NELBO: 35950521.82\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 379.57 .. KL_eta: 48.34 .. KL_alpha: 4179425.35 .. Rec_loss: 31987760.71 .. NELBO: 36167614.35\n",
      "****************************************************************************************************\n",
      "Epoch: 21 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 354.64 .. KL_eta: 50.43 .. KL_alpha: 4074788.43 .. Rec_loss: 31745993.27 .. NELBO: 35821186.55\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 389.12 .. KL_eta: 50.9 .. KL_alpha: 4041456.34 .. Rec_loss: 31845749.65 .. NELBO: 35887646.35\n",
      "****************************************************************************************************\n",
      "Epoch: 22 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 433.74 .. KL_eta: 49.57 .. KL_alpha: 3944803.07 .. Rec_loss: 31568632.91 .. NELBO: 35513918.36\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 398.53 .. KL_eta: 50.27 .. KL_alpha: 3924030.63 .. Rec_loss: 31958772.0 .. NELBO: 35883250.71\n",
      "****************************************************************************************************\n",
      "Epoch: 23 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 335.2 .. KL_eta: 50.41 .. KL_alpha: 3837214.34 .. Rec_loss: 32023603.45 .. NELBO: 35861203.09\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 406.58 .. KL_eta: 50.42 .. KL_alpha: 3818591.06 .. Rec_loss: 32035172.47 .. NELBO: 35854220.59\n",
      "****************************************************************************************************\n",
      "Epoch: 24 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 664.47 .. KL_eta: 56.42 .. KL_alpha: 3714448.73 .. Rec_loss: 31906302.36 .. NELBO: 35621472.0\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 608.19 .. KL_eta: 55.79 .. KL_alpha: 3694251.06 .. Rec_loss: 31888079.18 .. NELBO: 35582994.12\n",
      "****************************************************************************************************\n",
      "Epoch: 25 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 731.21 .. KL_eta: 51.24 .. KL_alpha: 3616473.52 .. Rec_loss: 31153629.09 .. NELBO: 34770885.45\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 672.24 .. KL_eta: 50.74 .. KL_alpha: 3605869.74 .. Rec_loss: 31979626.0 .. NELBO: 35586218.82\n",
      "****************************************************************************************************\n",
      "Epoch: 26 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 874.39 .. KL_eta: 51.51 .. KL_alpha: 3519685.57 .. Rec_loss: 31786148.0 .. NELBO: 35306760.0\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 969.66 .. KL_eta: 51.49 .. KL_alpha: 3498497.09 .. Rec_loss: 31881724.82 .. NELBO: 35381244.0\n",
      "****************************************************************************************************\n",
      "Epoch: 27 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 787.53 .. KL_eta: 52.04 .. KL_alpha: 3423046.34 .. Rec_loss: 31234165.09 .. NELBO: 34658050.73\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 775.31 .. KL_eta: 51.62 .. KL_alpha: 3411850.16 .. Rec_loss: 31814919.29 .. NELBO: 35227596.47\n",
      "****************************************************************************************************\n",
      "Epoch: 28 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 708.53 .. KL_eta: 49.75 .. KL_alpha: 3339082.48 .. Rec_loss: 32344023.82 .. NELBO: 35683864.73\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 774.18 .. KL_eta: 49.49 .. KL_alpha: 3327635.78 .. Rec_loss: 31804704.35 .. NELBO: 35133164.24\n",
      "****************************************************************************************************\n",
      "Epoch: 29 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1147.27 .. KL_eta: 49.77 .. KL_alpha: 3262400.11 .. Rec_loss: 31746499.27 .. NELBO: 35010096.36\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 969.69 .. KL_eta: 50.06 .. KL_alpha: 3254449.06 .. Rec_loss: 31915022.47 .. NELBO: 35170491.53\n",
      "****************************************************************************************************\n",
      "Epoch: 30 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 920.02 .. KL_eta: 50.52 .. KL_alpha: 3183043.8 .. Rec_loss: 31755219.82 .. NELBO: 34939233.45\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 1128.85 .. KL_eta: 50.85 .. KL_alpha: 3171413.85 .. Rec_loss: 31809551.41 .. NELBO: 34982144.47\n",
      "****************************************************************************************************\n",
      "Epoch: 31 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1336.8 .. KL_eta: 53.85 .. KL_alpha: 3124051.52 .. Rec_loss: 32116237.45 .. NELBO: 35241680.73\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 1181.14 .. KL_eta: 53.92 .. KL_alpha: 3109038.81 .. Rec_loss: 31813838.35 .. NELBO: 34924113.06\n",
      "****************************************************************************************************\n",
      "Epoch: 32 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1426.8 .. KL_eta: 54.69 .. KL_alpha: 3065115.0 .. Rec_loss: 31640259.27 .. NELBO: 34706856.36\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 1304.06 .. KL_eta: 54.51 .. KL_alpha: 3055608.43 .. Rec_loss: 31725409.06 .. NELBO: 34782376.47\n",
      "****************************************************************************************************\n",
      "Epoch: 33 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1281.2 .. KL_eta: 63.63 .. KL_alpha: 3009926.91 .. Rec_loss: 31577857.82 .. NELBO: 34589129.64\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 1159.99 .. KL_eta: 69.22 .. KL_alpha: 2997104.9 .. Rec_loss: 31746906.35 .. NELBO: 34745240.35\n",
      "****************************************************************************************************\n",
      "Epoch: 34 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1799.77 .. KL_eta: 64.38 .. KL_alpha: 2926519.73 .. Rec_loss: 31570158.73 .. NELBO: 34498541.82\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 1617.71 .. KL_eta: 71.13 .. KL_alpha: 2918017.47 .. Rec_loss: 31941562.71 .. NELBO: 34861268.47\n",
      "****************************************************************************************************\n",
      "Epoch: 35 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 1921.91 .. KL_eta: 80.74 .. KL_alpha: 2879225.05 .. Rec_loss: 32189826.0 .. NELBO: 35071054.0\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 1736.34 .. KL_eta: 79.96 .. KL_alpha: 2869182.44 .. Rec_loss: 31821514.12 .. NELBO: 34692513.29\n",
      "****************************************************************************************************\n",
      "Epoch: 36 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 2073.86 .. KL_eta: 113.72 .. KL_alpha: 2809230.16 .. Rec_loss: 31378453.45 .. NELBO: 34189872.0\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 2167.15 .. KL_eta: 99.85 .. KL_alpha: 2806296.31 .. Rec_loss: 31756485.06 .. NELBO: 34565049.06\n",
      "****************************************************************************************************\n",
      "Epoch: 37 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 2377.21 .. KL_eta: 178.99 .. KL_alpha: 2767180.89 .. Rec_loss: 31806568.0 .. NELBO: 34576305.45\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 2106.21 .. KL_eta: 158.84 .. KL_alpha: 2762426.57 .. Rec_loss: 31703476.94 .. NELBO: 34468169.29\n",
      "****************************************************************************************************\n",
      "Epoch: 38 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 2691.99 .. KL_eta: 126.06 .. KL_alpha: 2718358.43 .. Rec_loss: 31328813.64 .. NELBO: 34049990.36\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 2962.13 .. KL_eta: 132.35 .. KL_alpha: 2709168.85 .. Rec_loss: 31755301.29 .. NELBO: 34467565.29\n",
      "****************************************************************************************************\n",
      "Epoch: 39 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 2725.37 .. KL_eta: 167.56 .. KL_alpha: 2660482.11 .. Rec_loss: 31827588.36 .. NELBO: 34490963.64\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 2756.97 .. KL_eta: 138.97 .. KL_alpha: 2656351.79 .. Rec_loss: 31827138.71 .. NELBO: 34486387.18\n",
      "****************************************************************************************************\n",
      "Epoch: 40 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 2276.52 .. KL_eta: 113.14 .. KL_alpha: 2630295.45 .. Rec_loss: 31892306.55 .. NELBO: 34524991.27\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 2680.04 .. KL_eta: 128.53 .. KL_alpha: 2619636.6 .. Rec_loss: 31769588.71 .. NELBO: 34392033.53\n",
      "****************************************************************************************************\n",
      "Epoch: 41 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3176.48 .. KL_eta: 168.36 .. KL_alpha: 2565547.66 .. Rec_loss: 31650458.55 .. NELBO: 34219351.64\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 3262.71 .. KL_eta: 165.31 .. KL_alpha: 2563394.32 .. Rec_loss: 31668040.94 .. NELBO: 34234864.35\n",
      "****************************************************************************************************\n",
      "Epoch: 42 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3077.77 .. KL_eta: 285.43 .. KL_alpha: 2528555.7 .. Rec_loss: 31938342.36 .. NELBO: 34470261.27\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 2852.13 .. KL_eta: 274.29 .. KL_alpha: 2522519.51 .. Rec_loss: 31613690.71 .. NELBO: 34139336.35\n",
      "****************************************************************************************************\n",
      "Epoch: 43 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3236.13 .. KL_eta: 380.65 .. KL_alpha: 2483437.0 .. Rec_loss: 32330564.0 .. NELBO: 34817617.45\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 3042.25 .. KL_eta: 336.56 .. KL_alpha: 2477105.22 .. Rec_loss: 31634226.82 .. NELBO: 34114710.71\n",
      "****************************************************************************************************\n",
      "Epoch: 44 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3007.68 .. KL_eta: 392.21 .. KL_alpha: 2451376.73 .. Rec_loss: 31597647.09 .. NELBO: 34052423.64\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 2855.89 .. KL_eta: 431.47 .. KL_alpha: 2437787.41 .. Rec_loss: 31684237.06 .. NELBO: 34125312.0\n",
      "****************************************************************************************************\n",
      "Epoch: 45 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3348.36 .. KL_eta: 364.77 .. KL_alpha: 2409050.25 .. Rec_loss: 32193919.82 .. NELBO: 34606682.0\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 3160.62 .. KL_eta: 371.65 .. KL_alpha: 2401627.1 .. Rec_loss: 31666726.82 .. NELBO: 34071885.29\n",
      "****************************************************************************************************\n",
      "Epoch: 46 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3282.33 .. KL_eta: 420.81 .. KL_alpha: 2368445.95 .. Rec_loss: 31797235.64 .. NELBO: 34169385.45\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 3326.15 .. KL_eta: 418.16 .. KL_alpha: 2363718.85 .. Rec_loss: 31838310.59 .. NELBO: 34205774.35\n",
      "****************************************************************************************************\n",
      "Epoch: 47 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3256.9 .. KL_eta: 398.96 .. KL_alpha: 2323212.68 .. Rec_loss: 31631769.45 .. NELBO: 33958637.82\n",
      "****************************************************************************************************\n",
      "Epoch----->47 .. LR: 0.005 .. KL_theta: 3362.17 .. KL_eta: 430.06 .. KL_alpha: 2320978.94 .. Rec_loss: 31656370.59 .. NELBO: 33981141.53\n",
      "****************************************************************************************************\n",
      "Epoch: 48 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 3606.47 .. KL_eta: 552.46 .. KL_alpha: 2294991.3 .. Rec_loss: 31136808.0 .. NELBO: 33435958.0\n",
      "****************************************************************************************************\n",
      "Epoch----->48 .. LR: 0.005 .. KL_theta: 4114.65 .. KL_eta: 601.03 .. KL_alpha: 2289115.24 .. Rec_loss: 31645523.41 .. NELBO: 33939354.35\n",
      "****************************************************************************************************\n",
      "Epoch: 49 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4468.88 .. KL_eta: 541.71 .. KL_alpha: 2264412.34 .. Rec_loss: 31685781.45 .. NELBO: 33955204.18\n",
      "****************************************************************************************************\n",
      "Epoch----->49 .. LR: 0.005 .. KL_theta: 4312.18 .. KL_eta: 514.25 .. KL_alpha: 2253990.82 .. Rec_loss: 31502278.0 .. NELBO: 33761095.65\n",
      "****************************************************************************************************\n",
      "Epoch: 50 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4648.56 .. KL_eta: 474.16 .. KL_alpha: 2224054.55 .. Rec_loss: 31800708.36 .. NELBO: 34029885.82\n",
      "****************************************************************************************************\n",
      "Epoch----->50 .. LR: 0.005 .. KL_theta: 4549.82 .. KL_eta: 518.9 .. KL_alpha: 2220173.63 .. Rec_loss: 31717302.47 .. NELBO: 33942544.35\n",
      "****************************************************************************************************\n",
      "Epoch: 51 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4612.19 .. KL_eta: 571.01 .. KL_alpha: 2201033.61 .. Rec_loss: 32065241.45 .. NELBO: 34271457.82\n",
      "****************************************************************************************************\n",
      "Epoch----->51 .. LR: 0.005 .. KL_theta: 4513.51 .. KL_eta: 572.53 .. KL_alpha: 2194096.13 .. Rec_loss: 31419575.18 .. NELBO: 33618756.82\n",
      "****************************************************************************************************\n",
      "Epoch: 52 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4304.23 .. KL_eta: 568.22 .. KL_alpha: 2168202.07 .. Rec_loss: 31662449.45 .. NELBO: 33835523.82\n",
      "****************************************************************************************************\n",
      "Epoch----->52 .. LR: 0.005 .. KL_theta: 4471.15 .. KL_eta: 573.04 .. KL_alpha: 2161998.01 .. Rec_loss: 31646964.12 .. NELBO: 33814006.24\n",
      "****************************************************************************************************\n",
      "Epoch: 53 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4136.36 .. KL_eta: 555.58 .. KL_alpha: 2137873.93 .. Rec_loss: 31492884.73 .. NELBO: 33635450.73\n",
      "****************************************************************************************************\n",
      "Epoch----->53 .. LR: 0.005 .. KL_theta: 4090.79 .. KL_eta: 597.9 .. KL_alpha: 2134996.74 .. Rec_loss: 31482571.65 .. NELBO: 33622257.29\n",
      "****************************************************************************************************\n",
      "Epoch: 54 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4172.33 .. KL_eta: 504.06 .. KL_alpha: 2115171.24 .. Rec_loss: 31215268.0 .. NELBO: 33335116.18\n",
      "****************************************************************************************************\n",
      "Epoch----->54 .. LR: 0.005 .. KL_theta: 4638.46 .. KL_eta: 600.74 .. KL_alpha: 2112157.38 .. Rec_loss: 31536030.0 .. NELBO: 33653427.18\n",
      "****************************************************************************************************\n",
      "Epoch: 55 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5282.28 .. KL_eta: 634.72 .. KL_alpha: 2071894.93 .. Rec_loss: 31229154.36 .. NELBO: 33306967.09\n",
      "****************************************************************************************************\n",
      "Epoch----->55 .. LR: 0.005 .. KL_theta: 5052.71 .. KL_eta: 626.33 .. KL_alpha: 2070549.18 .. Rec_loss: 31580755.88 .. NELBO: 33656984.47\n",
      "****************************************************************************************************\n",
      "Epoch: 56 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5502.33 .. KL_eta: 595.1 .. KL_alpha: 2050549.9 .. Rec_loss: 31942489.64 .. NELBO: 33999137.82\n",
      "****************************************************************************************************\n",
      "Epoch----->56 .. LR: 0.005 .. KL_theta: 5170.25 .. KL_eta: 667.41 .. KL_alpha: 2042642.61 .. Rec_loss: 31349553.41 .. NELBO: 33398034.0\n",
      "****************************************************************************************************\n",
      "Epoch: 57 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5117.94 .. KL_eta: 691.89 .. KL_alpha: 2020221.68 .. Rec_loss: 31715244.18 .. NELBO: 33741275.82\n",
      "****************************************************************************************************\n",
      "Epoch----->57 .. LR: 0.005 .. KL_theta: 5021.01 .. KL_eta: 730.37 .. KL_alpha: 2015287.15 .. Rec_loss: 31428103.41 .. NELBO: 33449141.88\n",
      "****************************************************************************************************\n",
      "Epoch: 58 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4666.51 .. KL_eta: 794.35 .. KL_alpha: 1999080.7 .. Rec_loss: 31088622.73 .. NELBO: 33093164.0\n",
      "****************************************************************************************************\n",
      "Epoch----->58 .. LR: 0.005 .. KL_theta: 4776.41 .. KL_eta: 795.73 .. KL_alpha: 1994112.91 .. Rec_loss: 31342732.94 .. NELBO: 33342417.53\n",
      "****************************************************************************************************\n",
      "Epoch: 59 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4387.91 .. KL_eta: 704.91 .. KL_alpha: 1961193.55 .. Rec_loss: 31222682.55 .. NELBO: 33188968.55\n",
      "****************************************************************************************************\n",
      "Epoch----->59 .. LR: 0.005 .. KL_theta: 4825.8 .. KL_eta: 711.97 .. KL_alpha: 1952244.04 .. Rec_loss: 31415662.24 .. NELBO: 33373444.0\n",
      "****************************************************************************************************\n",
      "Epoch: 60 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5032.62 .. KL_eta: 684.84 .. KL_alpha: 1938551.22 .. Rec_loss: 31467524.91 .. NELBO: 33411794.36\n",
      "****************************************************************************************************\n",
      "Epoch----->60 .. LR: 0.005 .. KL_theta: 5065.86 .. KL_eta: 725.93 .. KL_alpha: 1932829.62 .. Rec_loss: 31547120.59 .. NELBO: 33485742.59\n",
      "****************************************************************************************************\n",
      "Epoch: 61 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4756.63 .. KL_eta: 875.6 .. KL_alpha: 1915055.76 .. Rec_loss: 31726559.27 .. NELBO: 33647248.55\n",
      "****************************************************************************************************\n",
      "Epoch----->61 .. LR: 0.005 .. KL_theta: 4818.82 .. KL_eta: 829.1 .. KL_alpha: 1906896.97 .. Rec_loss: 31483515.88 .. NELBO: 33396061.41\n",
      "****************************************************************************************************\n",
      "Epoch: 62 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4839.72 .. KL_eta: 579.36 .. KL_alpha: 1895062.92 .. Rec_loss: 31547512.91 .. NELBO: 33447995.82\n",
      "****************************************************************************************************\n",
      "Epoch----->62 .. LR: 0.005 .. KL_theta: 4451.8 .. KL_eta: 571.24 .. KL_alpha: 1889795.22 .. Rec_loss: 31470583.29 .. NELBO: 33365402.35\n",
      "****************************************************************************************************\n",
      "Epoch: 63 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5368.62 .. KL_eta: 681.0 .. KL_alpha: 1857866.9 .. Rec_loss: 31104894.0 .. NELBO: 32968810.18\n",
      "****************************************************************************************************\n",
      "Epoch----->63 .. LR: 0.005 .. KL_theta: 5087.95 .. KL_eta: 661.92 .. KL_alpha: 1855150.61 .. Rec_loss: 31526129.06 .. NELBO: 33387029.29\n",
      "****************************************************************************************************\n",
      "Epoch: 64 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4882.29 .. KL_eta: 633.21 .. KL_alpha: 1842649.49 .. Rec_loss: 31236626.55 .. NELBO: 33084791.82\n",
      "****************************************************************************************************\n",
      "Epoch----->64 .. LR: 0.005 .. KL_theta: 4785.58 .. KL_eta: 628.49 .. KL_alpha: 1839620.51 .. Rec_loss: 31373396.94 .. NELBO: 33218431.76\n",
      "****************************************************************************************************\n",
      "Epoch: 65 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4915.33 .. KL_eta: 523.93 .. KL_alpha: 1820005.48 .. Rec_loss: 31678698.73 .. NELBO: 33504144.55\n",
      "****************************************************************************************************\n",
      "Epoch----->65 .. LR: 0.005 .. KL_theta: 5178.13 .. KL_eta: 521.81 .. KL_alpha: 1811803.99 .. Rec_loss: 31317347.53 .. NELBO: 33134852.35\n",
      "****************************************************************************************************\n",
      "Epoch: 66 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 4869.84 .. KL_eta: 516.11 .. KL_alpha: 1800140.0 .. Rec_loss: 31033059.45 .. NELBO: 32838584.91\n",
      "****************************************************************************************************\n",
      "Epoch----->66 .. LR: 0.005 .. KL_theta: 4824.91 .. KL_eta: 504.8 .. KL_alpha: 1792004.59 .. Rec_loss: 31371589.06 .. NELBO: 33168923.06\n",
      "****************************************************************************************************\n",
      "Epoch: 67 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5764.87 .. KL_eta: 427.92 .. KL_alpha: 1769089.36 .. Rec_loss: 31498094.0 .. NELBO: 33273376.0\n",
      "****************************************************************************************************\n",
      "Epoch----->67 .. LR: 0.005 .. KL_theta: 5620.73 .. KL_eta: 438.87 .. KL_alpha: 1766716.35 .. Rec_loss: 31246954.0 .. NELBO: 33019729.88\n",
      "****************************************************************************************************\n",
      "Epoch: 68 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5432.52 .. KL_eta: 437.56 .. KL_alpha: 1761027.49 .. Rec_loss: 31665507.27 .. NELBO: 33432404.91\n",
      "****************************************************************************************************\n",
      "Epoch----->68 .. LR: 0.005 .. KL_theta: 5621.55 .. KL_eta: 443.96 .. KL_alpha: 1754402.87 .. Rec_loss: 31363075.88 .. NELBO: 33123544.12\n",
      "****************************************************************************************************\n",
      "Epoch: 69 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5591.93 .. KL_eta: 530.63 .. KL_alpha: 1732307.45 .. Rec_loss: 31625312.18 .. NELBO: 33363742.0\n",
      "****************************************************************************************************\n",
      "Epoch----->69 .. LR: 0.005 .. KL_theta: 5507.34 .. KL_eta: 536.08 .. KL_alpha: 1725513.08 .. Rec_loss: 31356151.53 .. NELBO: 33087707.65\n",
      "****************************************************************************************************\n",
      "Epoch: 70 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5966.47 .. KL_eta: 530.37 .. KL_alpha: 1714864.36 .. Rec_loss: 31449960.18 .. NELBO: 33171321.09\n",
      "****************************************************************************************************\n",
      "Epoch----->70 .. LR: 0.005 .. KL_theta: 5991.43 .. KL_eta: 550.01 .. KL_alpha: 1709766.32 .. Rec_loss: 31293500.71 .. NELBO: 33009808.24\n",
      "****************************************************************************************************\n",
      "Epoch: 71 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5321.3 .. KL_eta: 447.4 .. KL_alpha: 1690296.31 .. Rec_loss: 30948286.18 .. NELBO: 32644351.27\n",
      "****************************************************************************************************\n",
      "Epoch----->71 .. LR: 0.005 .. KL_theta: 5487.86 .. KL_eta: 449.86 .. KL_alpha: 1685870.18 .. Rec_loss: 31474585.88 .. NELBO: 33166394.35\n",
      "****************************************************************************************************\n",
      "Epoch: 72 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5563.2 .. KL_eta: 476.93 .. KL_alpha: 1670358.31 .. Rec_loss: 31647802.73 .. NELBO: 33324201.27\n",
      "****************************************************************************************************\n",
      "Epoch----->72 .. LR: 0.005 .. KL_theta: 5704.22 .. KL_eta: 468.13 .. KL_alpha: 1666406.91 .. Rec_loss: 31356305.41 .. NELBO: 33028884.94\n",
      "****************************************************************************************************\n",
      "Epoch: 73 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5601.32 .. KL_eta: 377.43 .. KL_alpha: 1654045.8 .. Rec_loss: 30966434.73 .. NELBO: 32626459.27\n",
      "****************************************************************************************************\n",
      "Epoch----->73 .. LR: 0.005 .. KL_theta: 5520.38 .. KL_eta: 414.13 .. KL_alpha: 1647571.64 .. Rec_loss: 31404736.59 .. NELBO: 33058242.59\n",
      "****************************************************************************************************\n",
      "Epoch: 74 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6077.27 .. KL_eta: 460.79 .. KL_alpha: 1631952.38 .. Rec_loss: 31256465.64 .. NELBO: 32894956.55\n",
      "****************************************************************************************************\n",
      "Epoch----->74 .. LR: 0.005 .. KL_theta: 6128.97 .. KL_eta: 495.99 .. KL_alpha: 1622246.01 .. Rec_loss: 31258093.88 .. NELBO: 32886964.94\n",
      "****************************************************************************************************\n",
      "Epoch: 75 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 5504.92 .. KL_eta: 546.67 .. KL_alpha: 1615008.9 .. Rec_loss: 31512233.82 .. NELBO: 33133294.36\n",
      "****************************************************************************************************\n",
      "Epoch----->75 .. LR: 0.005 .. KL_theta: 5685.24 .. KL_eta: 532.18 .. KL_alpha: 1609762.82 .. Rec_loss: 31191945.53 .. NELBO: 32807926.47\n",
      "****************************************************************************************************\n",
      "Epoch: 76 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6009.47 .. KL_eta: 563.51 .. KL_alpha: 1598704.84 .. Rec_loss: 31820090.91 .. NELBO: 33425368.73\n",
      "****************************************************************************************************\n",
      "Epoch----->76 .. LR: 0.005 .. KL_theta: 6078.71 .. KL_eta: 526.04 .. KL_alpha: 1597262.68 .. Rec_loss: 31356899.06 .. NELBO: 32960766.24\n",
      "****************************************************************************************************\n",
      "Epoch: 77 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6099.57 .. KL_eta: 551.03 .. KL_alpha: 1581635.11 .. Rec_loss: 31247830.18 .. NELBO: 32836116.18\n",
      "****************************************************************************************************\n",
      "Epoch----->77 .. LR: 0.005 .. KL_theta: 5849.06 .. KL_eta: 507.25 .. KL_alpha: 1579382.22 .. Rec_loss: 31383019.76 .. NELBO: 32968758.82\n",
      "****************************************************************************************************\n",
      "Epoch: 78 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6480.33 .. KL_eta: 414.91 .. KL_alpha: 1558204.91 .. Rec_loss: 31213741.82 .. NELBO: 32778842.18\n",
      "****************************************************************************************************\n",
      "Epoch----->78 .. LR: 0.005 .. KL_theta: 6211.58 .. KL_eta: 419.27 .. KL_alpha: 1556569.37 .. Rec_loss: 31287091.88 .. NELBO: 32850292.12\n",
      "****************************************************************************************************\n",
      "Epoch: 79 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6955.27 .. KL_eta: 470.9 .. KL_alpha: 1543974.48 .. Rec_loss: 31225908.73 .. NELBO: 32777310.18\n",
      "****************************************************************************************************\n",
      "Epoch----->79 .. LR: 0.005 .. KL_theta: 6793.64 .. KL_eta: 500.7 .. KL_alpha: 1544644.04 .. Rec_loss: 31286055.76 .. NELBO: 32837994.35\n",
      "****************************************************************************************************\n",
      "Epoch: 80 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6877.4 .. KL_eta: 421.01 .. KL_alpha: 1535147.73 .. Rec_loss: 31143580.18 .. NELBO: 32686026.18\n",
      "****************************************************************************************************\n",
      "Epoch----->80 .. LR: 0.005 .. KL_theta: 7003.01 .. KL_eta: 405.9 .. KL_alpha: 1534422.0 .. Rec_loss: 31308208.59 .. NELBO: 32850039.29\n",
      "****************************************************************************************************\n",
      "Epoch: 81 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6828.13 .. KL_eta: 398.92 .. KL_alpha: 1517078.67 .. Rec_loss: 31431462.73 .. NELBO: 32955768.0\n",
      "****************************************************************************************************\n",
      "Epoch----->81 .. LR: 0.005 .. KL_theta: 6919.87 .. KL_eta: 447.32 .. KL_alpha: 1517218.58 .. Rec_loss: 31338851.06 .. NELBO: 32863436.24\n",
      "****************************************************************************************************\n",
      "Epoch: 82 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6778.53 .. KL_eta: 489.89 .. KL_alpha: 1494995.52 .. Rec_loss: 31411223.64 .. NELBO: 32913487.09\n",
      "****************************************************************************************************\n",
      "Epoch----->82 .. LR: 0.005 .. KL_theta: 6985.88 .. KL_eta: 464.38 .. KL_alpha: 1490498.61 .. Rec_loss: 31242646.35 .. NELBO: 32740594.82\n",
      "****************************************************************************************************\n",
      "Epoch: 83 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6788.83 .. KL_eta: 436.87 .. KL_alpha: 1485039.18 .. Rec_loss: 31247302.0 .. NELBO: 32739566.91\n",
      "****************************************************************************************************\n",
      "Epoch----->83 .. LR: 0.005 .. KL_theta: 6974.98 .. KL_eta: 422.65 .. KL_alpha: 1483604.3 .. Rec_loss: 31162501.65 .. NELBO: 32653504.0\n",
      "****************************************************************************************************\n",
      "Epoch: 84 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6896.66 .. KL_eta: 398.03 .. KL_alpha: 1460423.28 .. Rec_loss: 31457703.27 .. NELBO: 32925421.09\n",
      "****************************************************************************************************\n",
      "Epoch----->84 .. LR: 0.005 .. KL_theta: 7180.74 .. KL_eta: 452.13 .. KL_alpha: 1460373.2 .. Rec_loss: 31146999.06 .. NELBO: 32615005.18\n",
      "****************************************************************************************************\n",
      "Epoch: 85 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6257.79 .. KL_eta: 441.69 .. KL_alpha: 1447968.12 .. Rec_loss: 31076295.09 .. NELBO: 32530962.55\n",
      "****************************************************************************************************\n",
      "Epoch----->85 .. LR: 0.005 .. KL_theta: 6620.74 .. KL_eta: 443.24 .. KL_alpha: 1445531.28 .. Rec_loss: 31171295.53 .. NELBO: 32623890.24\n",
      "****************************************************************************************************\n",
      "Epoch: 86 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6915.14 .. KL_eta: 407.91 .. KL_alpha: 1437048.31 .. Rec_loss: 31309482.91 .. NELBO: 32753854.55\n",
      "****************************************************************************************************\n",
      "Epoch----->86 .. LR: 0.005 .. KL_theta: 7003.2 .. KL_eta: 408.46 .. KL_alpha: 1431461.37 .. Rec_loss: 31263073.65 .. NELBO: 32701946.59\n",
      "****************************************************************************************************\n",
      "Epoch: 87 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6926.79 .. KL_eta: 417.61 .. KL_alpha: 1419216.92 .. Rec_loss: 31144975.27 .. NELBO: 32571537.27\n",
      "****************************************************************************************************\n",
      "Epoch----->87 .. LR: 0.005 .. KL_theta: 7161.91 .. KL_eta: 401.91 .. KL_alpha: 1417612.0 .. Rec_loss: 31233030.0 .. NELBO: 32658206.47\n",
      "****************************************************************************************************\n",
      "Epoch: 88 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7284.55 .. KL_eta: 359.24 .. KL_alpha: 1402001.0 .. Rec_loss: 30971313.45 .. NELBO: 32380959.09\n",
      "****************************************************************************************************\n",
      "Epoch----->88 .. LR: 0.005 .. KL_theta: 7596.8 .. KL_eta: 362.62 .. KL_alpha: 1402124.35 .. Rec_loss: 31221558.0 .. NELBO: 32631642.12\n",
      "****************************************************************************************************\n",
      "Epoch: 89 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7585.82 .. KL_eta: 352.47 .. KL_alpha: 1393750.51 .. Rec_loss: 31623452.73 .. NELBO: 33025141.09\n",
      "****************************************************************************************************\n",
      "Epoch----->89 .. LR: 0.005 .. KL_theta: 7348.66 .. KL_eta: 348.71 .. KL_alpha: 1390912.04 .. Rec_loss: 31102358.82 .. NELBO: 32500967.76\n",
      "****************************************************************************************************\n",
      "Epoch: 90 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7602.28 .. KL_eta: 351.82 .. KL_alpha: 1378071.55 .. Rec_loss: 31268738.91 .. NELBO: 32654764.55\n",
      "****************************************************************************************************\n",
      "Epoch----->90 .. LR: 0.005 .. KL_theta: 7371.55 .. KL_eta: 341.63 .. KL_alpha: 1375946.46 .. Rec_loss: 31160078.59 .. NELBO: 32543737.88\n",
      "****************************************************************************************************\n",
      "Epoch: 91 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7444.46 .. KL_eta: 311.53 .. KL_alpha: 1367516.83 .. Rec_loss: 32005122.36 .. NELBO: 33380394.73\n",
      "****************************************************************************************************\n",
      "Epoch----->91 .. LR: 0.005 .. KL_theta: 7349.11 .. KL_eta: 324.58 .. KL_alpha: 1362996.34 .. Rec_loss: 31188348.12 .. NELBO: 32559017.88\n",
      "****************************************************************************************************\n",
      "Epoch: 92 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7706.31 .. KL_eta: 353.32 .. KL_alpha: 1346339.81 .. Rec_loss: 31144602.73 .. NELBO: 32499002.18\n",
      "****************************************************************************************************\n",
      "Epoch----->92 .. LR: 0.005 .. KL_theta: 7508.47 .. KL_eta: 342.14 .. KL_alpha: 1344761.8 .. Rec_loss: 31181833.88 .. NELBO: 32534446.35\n",
      "****************************************************************************************************\n",
      "Epoch: 93 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7187.68 .. KL_eta: 347.99 .. KL_alpha: 1338385.98 .. Rec_loss: 30758140.36 .. NELBO: 32104062.18\n",
      "****************************************************************************************************\n",
      "Epoch----->93 .. LR: 0.005 .. KL_theta: 7405.57 .. KL_eta: 347.02 .. KL_alpha: 1335285.26 .. Rec_loss: 31153695.06 .. NELBO: 32496733.06\n",
      "****************************************************************************************************\n",
      "Epoch: 94 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7531.41 .. KL_eta: 308.44 .. KL_alpha: 1327730.09 .. Rec_loss: 31388732.36 .. NELBO: 32724302.0\n",
      "****************************************************************************************************\n",
      "Epoch----->94 .. LR: 0.005 .. KL_theta: 7359.97 .. KL_eta: 320.71 .. KL_alpha: 1323324.46 .. Rec_loss: 31106465.41 .. NELBO: 32437470.35\n",
      "****************************************************************************************************\n",
      "Epoch: 95 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7586.93 .. KL_eta: 306.89 .. KL_alpha: 1307326.67 .. Rec_loss: 31177881.64 .. NELBO: 32493101.64\n",
      "****************************************************************************************************\n",
      "Epoch----->95 .. LR: 0.005 .. KL_theta: 7588.53 .. KL_eta: 311.42 .. KL_alpha: 1304538.64 .. Rec_loss: 31250166.35 .. NELBO: 32562604.71\n",
      "****************************************************************************************************\n",
      "Epoch: 96 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7463.67 .. KL_eta: 381.34 .. KL_alpha: 1295860.3 .. Rec_loss: 31127019.45 .. NELBO: 32430724.55\n",
      "****************************************************************************************************\n",
      "Epoch----->96 .. LR: 0.005 .. KL_theta: 7785.85 .. KL_eta: 375.22 .. KL_alpha: 1293255.93 .. Rec_loss: 31213315.41 .. NELBO: 32514732.47\n",
      "****************************************************************************************************\n",
      "Epoch: 97 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7866.23 .. KL_eta: 343.91 .. KL_alpha: 1282864.56 .. Rec_loss: 31421990.73 .. NELBO: 32713065.27\n",
      "****************************************************************************************************\n",
      "Epoch----->97 .. LR: 0.005 .. KL_theta: 7684.05 .. KL_eta: 342.83 .. KL_alpha: 1282382.56 .. Rec_loss: 31088149.41 .. NELBO: 32378558.47\n",
      "****************************************************************************************************\n",
      "Epoch: 98 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8043.57 .. KL_eta: 353.57 .. KL_alpha: 1278588.94 .. Rec_loss: 31335181.64 .. NELBO: 32622167.82\n",
      "****************************************************************************************************\n",
      "Epoch----->98 .. LR: 0.005 .. KL_theta: 7771.47 .. KL_eta: 337.85 .. KL_alpha: 1275547.08 .. Rec_loss: 31157725.53 .. NELBO: 32441382.0\n",
      "****************************************************************************************************\n",
      "Epoch: 99 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7801.62 .. KL_eta: 321.93 .. KL_alpha: 1263765.45 .. Rec_loss: 31108393.45 .. NELBO: 32380282.36\n",
      "****************************************************************************************************\n",
      "Epoch----->99 .. LR: 0.005 .. KL_theta: 7710.17 .. KL_eta: 322.7 .. KL_alpha: 1261784.88 .. Rec_loss: 31181290.94 .. NELBO: 32451108.47\n",
      "****************************************************************************************************\n",
      "Epoch: 100 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8179.46 .. KL_eta: 362.46 .. KL_alpha: 1245484.39 .. Rec_loss: 31332204.73 .. NELBO: 32586230.73\n",
      "****************************************************************************************************\n",
      "Epoch----->100 .. LR: 0.005 .. KL_theta: 7806.03 .. KL_eta: 353.82 .. KL_alpha: 1243738.44 .. Rec_loss: 31177535.41 .. NELBO: 32429433.53\n",
      "****************************************************************************************************\n",
      "Epoch: 101 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8651.7 .. KL_eta: 303.14 .. KL_alpha: 1227953.7 .. Rec_loss: 30837728.36 .. NELBO: 32074637.09\n",
      "****************************************************************************************************\n",
      "Epoch----->101 .. LR: 0.005 .. KL_theta: 8498.83 .. KL_eta: 287.32 .. KL_alpha: 1230362.38 .. Rec_loss: 31164148.47 .. NELBO: 32403297.18\n",
      "****************************************************************************************************\n",
      "Epoch: 102 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8285.65 .. KL_eta: 231.11 .. KL_alpha: 1221197.74 .. Rec_loss: 31254145.64 .. NELBO: 32483860.18\n",
      "****************************************************************************************************\n",
      "Epoch----->102 .. LR: 0.005 .. KL_theta: 8454.17 .. KL_eta: 248.04 .. KL_alpha: 1217114.18 .. Rec_loss: 31170718.82 .. NELBO: 32396535.29\n",
      "****************************************************************************************************\n",
      "Epoch: 103 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7880.97 .. KL_eta: 342.51 .. KL_alpha: 1210374.85 .. Rec_loss: 30955441.27 .. NELBO: 32174038.91\n",
      "****************************************************************************************************\n",
      "Epoch----->103 .. LR: 0.005 .. KL_theta: 8314.83 .. KL_eta: 320.82 .. KL_alpha: 1208179.32 .. Rec_loss: 31070120.24 .. NELBO: 32286934.94\n",
      "****************************************************************************************************\n",
      "Epoch: 104 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8285.68 .. KL_eta: 268.96 .. KL_alpha: 1200490.42 .. Rec_loss: 31355500.91 .. NELBO: 32564546.0\n",
      "****************************************************************************************************\n",
      "Epoch----->104 .. LR: 0.005 .. KL_theta: 8161.71 .. KL_eta: 293.21 .. KL_alpha: 1196519.18 .. Rec_loss: 31056922.59 .. NELBO: 32261896.47\n",
      "****************************************************************************************************\n",
      "Epoch: 105 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8237.26 .. KL_eta: 336.53 .. KL_alpha: 1185798.86 .. Rec_loss: 30715403.27 .. NELBO: 31909776.18\n",
      "****************************************************************************************************\n",
      "Epoch----->105 .. LR: 0.005 .. KL_theta: 8364.09 .. KL_eta: 334.37 .. KL_alpha: 1184579.2 .. Rec_loss: 31096581.65 .. NELBO: 32289859.65\n",
      "****************************************************************************************************\n",
      "Epoch: 106 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8232.64 .. KL_eta: 325.51 .. KL_alpha: 1177150.32 .. Rec_loss: 30562476.91 .. NELBO: 31748185.27\n",
      "****************************************************************************************************\n",
      "Epoch----->106 .. LR: 0.005 .. KL_theta: 8295.18 .. KL_eta: 326.25 .. KL_alpha: 1175195.15 .. Rec_loss: 31068160.94 .. NELBO: 32251977.53\n",
      "****************************************************************************************************\n",
      "Epoch: 107 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8441.12 .. KL_eta: 355.76 .. KL_alpha: 1168922.3 .. Rec_loss: 31498498.91 .. NELBO: 32676218.0\n",
      "****************************************************************************************************\n",
      "Epoch----->107 .. LR: 0.005 .. KL_theta: 8213.99 .. KL_eta: 347.8 .. KL_alpha: 1167374.19 .. Rec_loss: 30995724.94 .. NELBO: 32171660.71\n",
      "****************************************************************************************************\n",
      "Epoch: 108 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8368.06 .. KL_eta: 361.81 .. KL_alpha: 1157632.81 .. Rec_loss: 31018708.36 .. NELBO: 32185070.91\n",
      "****************************************************************************************************\n",
      "Epoch----->108 .. LR: 0.005 .. KL_theta: 8304.23 .. KL_eta: 361.74 .. KL_alpha: 1154697.67 .. Rec_loss: 31005093.41 .. NELBO: 32168456.71\n",
      "****************************************************************************************************\n",
      "Epoch: 109 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8588.11 .. KL_eta: 357.75 .. KL_alpha: 1145638.74 .. Rec_loss: 31694080.36 .. NELBO: 32848665.27\n",
      "****************************************************************************************************\n",
      "Epoch----->109 .. LR: 0.005 .. KL_theta: 8170.85 .. KL_eta: 353.03 .. KL_alpha: 1143596.32 .. Rec_loss: 30992811.06 .. NELBO: 32144931.53\n",
      "****************************************************************************************************\n",
      "Epoch: 110 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8340.51 .. KL_eta: 329.08 .. KL_alpha: 1137571.64 .. Rec_loss: 30872180.18 .. NELBO: 32018421.45\n",
      "****************************************************************************************************\n",
      "Epoch----->110 .. LR: 0.005 .. KL_theta: 8292.95 .. KL_eta: 323.49 .. KL_alpha: 1132619.62 .. Rec_loss: 31115972.35 .. NELBO: 32257208.35\n",
      "****************************************************************************************************\n",
      "Epoch: 111 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8300.7 .. KL_eta: 337.16 .. KL_alpha: 1126513.23 .. Rec_loss: 31070579.27 .. NELBO: 32205730.18\n",
      "****************************************************************************************************\n",
      "Epoch----->111 .. LR: 0.005 .. KL_theta: 8225.8 .. KL_eta: 331.43 .. KL_alpha: 1122361.27 .. Rec_loss: 31013416.71 .. NELBO: 32144335.18\n",
      "****************************************************************************************************\n",
      "Epoch: 112 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8527.42 .. KL_eta: 292.13 .. KL_alpha: 1117153.99 .. Rec_loss: 30930222.91 .. NELBO: 32056196.36\n",
      "****************************************************************************************************\n",
      "Epoch----->112 .. LR: 0.005 .. KL_theta: 8611.9 .. KL_eta: 291.01 .. KL_alpha: 1113195.03 .. Rec_loss: 31078507.76 .. NELBO: 32200605.29\n",
      "****************************************************************************************************\n",
      "Epoch: 113 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8227.48 .. KL_eta: 292.89 .. KL_alpha: 1106002.26 .. Rec_loss: 30947632.18 .. NELBO: 32062155.45\n",
      "****************************************************************************************************\n",
      "Epoch----->113 .. LR: 0.005 .. KL_theta: 8258.6 .. KL_eta: 288.77 .. KL_alpha: 1104945.18 .. Rec_loss: 30999353.76 .. NELBO: 32112846.71\n",
      "****************************************************************************************************\n",
      "Epoch: 114 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8562.06 .. KL_eta: 284.84 .. KL_alpha: 1092491.43 .. Rec_loss: 31359177.64 .. NELBO: 32460516.18\n",
      "****************************************************************************************************\n",
      "Epoch----->114 .. LR: 0.005 .. KL_theta: 8440.41 .. KL_eta: 296.97 .. KL_alpha: 1091947.88 .. Rec_loss: 31142150.35 .. NELBO: 32242835.76\n",
      "****************************************************************************************************\n",
      "Epoch: 115 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8414.44 .. KL_eta: 285.68 .. KL_alpha: 1082062.78 .. Rec_loss: 30449116.0 .. NELBO: 31539878.73\n",
      "****************************************************************************************************\n",
      "Epoch----->115 .. LR: 0.005 .. KL_theta: 8487.0 .. KL_eta: 274.9 .. KL_alpha: 1081368.16 .. Rec_loss: 30941171.29 .. NELBO: 32031301.41\n",
      "****************************************************************************************************\n",
      "Epoch: 116 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8827.67 .. KL_eta: 290.75 .. KL_alpha: 1072536.19 .. Rec_loss: 31589389.09 .. NELBO: 32671044.0\n",
      "****************************************************************************************************\n",
      "Epoch----->116 .. LR: 0.005 .. KL_theta: 8814.34 .. KL_eta: 288.11 .. KL_alpha: 1072341.27 .. Rec_loss: 31024448.94 .. NELBO: 32105892.82\n",
      "****************************************************************************************************\n",
      "Epoch: 117 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8167.95 .. KL_eta: 286.91 .. KL_alpha: 1068676.78 .. Rec_loss: 30341517.27 .. NELBO: 31418649.45\n",
      "****************************************************************************************************\n",
      "Epoch----->117 .. LR: 0.005 .. KL_theta: 8517.26 .. KL_eta: 282.23 .. KL_alpha: 1067060.68 .. Rec_loss: 31124386.24 .. NELBO: 32200246.82\n",
      "****************************************************************************************************\n",
      "Epoch: 118 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8553.8 .. KL_eta: 258.28 .. KL_alpha: 1053152.15 .. Rec_loss: 31025639.27 .. NELBO: 32087603.82\n",
      "****************************************************************************************************\n",
      "Epoch----->118 .. LR: 0.005 .. KL_theta: 8591.94 .. KL_eta: 266.13 .. KL_alpha: 1051231.4 .. Rec_loss: 31089525.65 .. NELBO: 32149615.29\n",
      "****************************************************************************************************\n",
      "Epoch: 119 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8555.11 .. KL_eta: 255.37 .. KL_alpha: 1043497.91 .. Rec_loss: 31166232.55 .. NELBO: 32218540.91\n",
      "****************************************************************************************************\n",
      "Epoch----->119 .. LR: 0.005 .. KL_theta: 8534.02 .. KL_eta: 250.16 .. KL_alpha: 1043530.68 .. Rec_loss: 30967727.41 .. NELBO: 32020042.24\n",
      "****************************************************************************************************\n",
      "Epoch: 120 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8542.9 .. KL_eta: 248.85 .. KL_alpha: 1037838.09 .. Rec_loss: 30961749.64 .. NELBO: 32008379.27\n",
      "****************************************************************************************************\n",
      "Epoch----->120 .. LR: 0.005 .. KL_theta: 8496.19 .. KL_eta: 251.41 .. KL_alpha: 1033957.58 .. Rec_loss: 30961222.12 .. NELBO: 32003927.18\n",
      "****************************************************************************************************\n",
      "Epoch: 121 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8633.37 .. KL_eta: 267.46 .. KL_alpha: 1032593.81 .. Rec_loss: 31099619.45 .. NELBO: 32141114.18\n",
      "****************************************************************************************************\n",
      "Epoch----->121 .. LR: 0.005 .. KL_theta: 8618.5 .. KL_eta: 259.25 .. KL_alpha: 1029812.9 .. Rec_loss: 30929082.47 .. NELBO: 31967773.41\n",
      "****************************************************************************************************\n",
      "Epoch: 122 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8624.08 .. KL_eta: 292.04 .. KL_alpha: 1019624.27 .. Rec_loss: 30905757.09 .. NELBO: 31934297.45\n",
      "****************************************************************************************************\n",
      "Epoch----->122 .. LR: 0.005 .. KL_theta: 8814.94 .. KL_eta: 287.85 .. KL_alpha: 1015916.25 .. Rec_loss: 31162910.47 .. NELBO: 32187930.12\n",
      "****************************************************************************************************\n",
      "Epoch: 123 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8778.25 .. KL_eta: 249.46 .. KL_alpha: 1013167.61 .. Rec_loss: 31147704.55 .. NELBO: 32169899.27\n",
      "****************************************************************************************************\n",
      "Epoch----->123 .. LR: 0.005 .. KL_theta: 8829.39 .. KL_eta: 249.85 .. KL_alpha: 1008488.26 .. Rec_loss: 31003849.06 .. NELBO: 32021416.12\n",
      "****************************************************************************************************\n",
      "Epoch: 124 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8766.31 .. KL_eta: 243.05 .. KL_alpha: 1000921.52 .. Rec_loss: 30685362.91 .. NELBO: 31695293.09\n",
      "****************************************************************************************************\n",
      "Epoch----->124 .. LR: 0.005 .. KL_theta: 8877.33 .. KL_eta: 248.0 .. KL_alpha: 998830.87 .. Rec_loss: 31034980.12 .. NELBO: 32042935.76\n",
      "****************************************************************************************************\n",
      "Epoch: 125 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8737.72 .. KL_eta: 269.14 .. KL_alpha: 991893.56 .. Rec_loss: 30543497.27 .. NELBO: 31544397.45\n",
      "****************************************************************************************************\n",
      "Epoch----->125 .. LR: 0.005 .. KL_theta: 8775.53 .. KL_eta: 267.71 .. KL_alpha: 991554.69 .. Rec_loss: 31037116.12 .. NELBO: 32037713.88\n",
      "****************************************************************************************************\n",
      "Epoch: 126 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8700.92 .. KL_eta: 227.19 .. KL_alpha: 982936.62 .. Rec_loss: 30987817.09 .. NELBO: 31979682.0\n",
      "****************************************************************************************************\n",
      "Epoch----->126 .. LR: 0.005 .. KL_theta: 8702.82 .. KL_eta: 229.42 .. KL_alpha: 979799.22 .. Rec_loss: 31066899.53 .. NELBO: 32055631.06\n",
      "****************************************************************************************************\n",
      "Epoch: 127 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8558.22 .. KL_eta: 249.35 .. KL_alpha: 975450.83 .. Rec_loss: 31166442.18 .. NELBO: 32150700.18\n",
      "****************************************************************************************************\n",
      "Epoch----->127 .. LR: 0.005 .. KL_theta: 8517.95 .. KL_eta: 254.14 .. KL_alpha: 974238.23 .. Rec_loss: 30944175.65 .. NELBO: 31927185.76\n",
      "****************************************************************************************************\n",
      "Epoch: 128 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8680.4 .. KL_eta: 240.3 .. KL_alpha: 962784.43 .. Rec_loss: 31158207.45 .. NELBO: 32129912.73\n",
      "****************************************************************************************************\n",
      "Epoch----->128 .. LR: 0.005 .. KL_theta: 8807.13 .. KL_eta: 245.57 .. KL_alpha: 961827.94 .. Rec_loss: 31087826.82 .. NELBO: 32058707.53\n",
      "****************************************************************************************************\n",
      "Epoch: 129 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8765.63 .. KL_eta: 261.52 .. KL_alpha: 953281.02 .. Rec_loss: 30586074.73 .. NELBO: 31548382.73\n",
      "****************************************************************************************************\n",
      "Epoch----->129 .. LR: 0.005 .. KL_theta: 8848.41 .. KL_eta: 263.63 .. KL_alpha: 953048.65 .. Rec_loss: 30988214.24 .. NELBO: 31950374.94\n",
      "****************************************************************************************************\n",
      "Epoch: 130 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8712.16 .. KL_eta: 266.51 .. KL_alpha: 945451.66 .. Rec_loss: 31057703.82 .. NELBO: 32012134.18\n",
      "****************************************************************************************************\n",
      "Epoch----->130 .. LR: 0.005 .. KL_theta: 8721.84 .. KL_eta: 260.61 .. KL_alpha: 943897.64 .. Rec_loss: 31099585.53 .. NELBO: 32052465.41\n",
      "****************************************************************************************************\n",
      "Epoch: 131 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8845.29 .. KL_eta: 268.82 .. KL_alpha: 935252.89 .. Rec_loss: 30628500.0 .. NELBO: 31572866.91\n",
      "****************************************************************************************************\n",
      "Epoch----->131 .. LR: 0.005 .. KL_theta: 9009.7 .. KL_eta: 263.41 .. KL_alpha: 933971.26 .. Rec_loss: 30920397.53 .. NELBO: 31863641.65\n",
      "****************************************************************************************************\n",
      "Epoch: 132 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8847.45 .. KL_eta: 254.88 .. KL_alpha: 933501.8 .. Rec_loss: 31071996.73 .. NELBO: 32014601.09\n",
      "****************************************************************************************************\n",
      "Epoch----->132 .. LR: 0.005 .. KL_theta: 8859.33 .. KL_eta: 271.14 .. KL_alpha: 931403.65 .. Rec_loss: 31041002.24 .. NELBO: 31981536.24\n",
      "****************************************************************************************************\n",
      "Epoch: 133 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8819.82 .. KL_eta: 278.76 .. KL_alpha: 925712.21 .. Rec_loss: 30856995.64 .. NELBO: 31791807.45\n",
      "****************************************************************************************************\n",
      "Epoch----->133 .. LR: 0.005 .. KL_theta: 8830.28 .. KL_eta: 274.42 .. KL_alpha: 921126.26 .. Rec_loss: 31008882.82 .. NELBO: 31939114.35\n",
      "****************************************************************************************************\n",
      "Epoch: 134 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8966.46 .. KL_eta: 271.82 .. KL_alpha: 919668.55 .. Rec_loss: 31217784.55 .. NELBO: 32146691.27\n",
      "****************************************************************************************************\n",
      "Epoch----->134 .. LR: 0.005 .. KL_theta: 8847.83 .. KL_eta: 267.32 .. KL_alpha: 917022.66 .. Rec_loss: 31012057.18 .. NELBO: 31938195.06\n",
      "****************************************************************************************************\n",
      "Epoch: 135 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9031.65 .. KL_eta: 262.06 .. KL_alpha: 914102.85 .. Rec_loss: 31150451.45 .. NELBO: 32073847.64\n",
      "****************************************************************************************************\n",
      "Epoch----->135 .. LR: 0.005 .. KL_theta: 8855.28 .. KL_eta: 266.56 .. KL_alpha: 910556.85 .. Rec_loss: 30941998.94 .. NELBO: 31861677.53\n",
      "****************************************************************************************************\n",
      "Epoch: 136 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9045.34 .. KL_eta: 260.66 .. KL_alpha: 905360.87 .. Rec_loss: 30955268.55 .. NELBO: 31869934.73\n",
      "****************************************************************************************************\n",
      "Epoch----->136 .. LR: 0.005 .. KL_theta: 9032.14 .. KL_eta: 257.78 .. KL_alpha: 900190.24 .. Rec_loss: 31134233.18 .. NELBO: 32043712.59\n",
      "****************************************************************************************************\n",
      "Epoch: 137 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9072.33 .. KL_eta: 271.1 .. KL_alpha: 892460.08 .. Rec_loss: 30789095.82 .. NELBO: 31690899.27\n",
      "****************************************************************************************************\n",
      "Epoch----->137 .. LR: 0.005 .. KL_theta: 8996.18 .. KL_eta: 270.99 .. KL_alpha: 888930.49 .. Rec_loss: 30975129.88 .. NELBO: 31873327.41\n",
      "****************************************************************************************************\n",
      "Epoch: 138 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8941.79 .. KL_eta: 254.61 .. KL_alpha: 884520.6 .. Rec_loss: 30891649.27 .. NELBO: 31785366.0\n",
      "****************************************************************************************************\n",
      "Epoch----->138 .. LR: 0.005 .. KL_theta: 9002.15 .. KL_eta: 262.92 .. KL_alpha: 885965.46 .. Rec_loss: 31115802.0 .. NELBO: 32011032.47\n",
      "****************************************************************************************************\n",
      "Epoch: 139 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8918.79 .. KL_eta: 278.85 .. KL_alpha: 876677.62 .. Rec_loss: 31081163.82 .. NELBO: 31967038.73\n",
      "****************************************************************************************************\n",
      "Epoch----->139 .. LR: 0.005 .. KL_theta: 8708.47 .. KL_eta: 284.59 .. KL_alpha: 875842.35 .. Rec_loss: 30990968.47 .. NELBO: 31875803.53\n",
      "****************************************************************************************************\n",
      "Epoch: 140 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9230.74 .. KL_eta: 260.66 .. KL_alpha: 869176.59 .. Rec_loss: 31280932.0 .. NELBO: 32159599.45\n",
      "****************************************************************************************************\n",
      "Epoch----->140 .. LR: 0.005 .. KL_theta: 9021.64 .. KL_eta: 259.72 .. KL_alpha: 867819.12 .. Rec_loss: 31044285.41 .. NELBO: 31921385.88\n",
      "****************************************************************************************************\n",
      "Epoch: 141 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8619.7 .. KL_eta: 283.06 .. KL_alpha: 865597.95 .. Rec_loss: 31344446.18 .. NELBO: 32218946.73\n",
      "****************************************************************************************************\n",
      "Epoch----->141 .. LR: 0.005 .. KL_theta: 8989.78 .. KL_eta: 272.82 .. KL_alpha: 863790.63 .. Rec_loss: 30985267.18 .. NELBO: 31858320.71\n",
      "****************************************************************************************************\n",
      "Epoch: 142 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8837.75 .. KL_eta: 264.93 .. KL_alpha: 858779.61 .. Rec_loss: 31092441.45 .. NELBO: 31960323.82\n",
      "****************************************************************************************************\n",
      "Epoch----->142 .. LR: 0.005 .. KL_theta: 8928.93 .. KL_eta: 265.88 .. KL_alpha: 856142.35 .. Rec_loss: 30895874.47 .. NELBO: 31761211.76\n",
      "****************************************************************************************************\n",
      "Epoch: 143 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8992.61 .. KL_eta: 277.99 .. KL_alpha: 848285.75 .. Rec_loss: 30714288.0 .. NELBO: 31571844.91\n",
      "****************************************************************************************************\n",
      "Epoch----->143 .. LR: 0.005 .. KL_theta: 8974.2 .. KL_eta: 272.54 .. KL_alpha: 847227.17 .. Rec_loss: 31004835.65 .. NELBO: 31861309.88\n",
      "****************************************************************************************************\n",
      "Epoch: 144 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8540.5 .. KL_eta: 269.67 .. KL_alpha: 839907.81 .. Rec_loss: 30956861.27 .. NELBO: 31805579.27\n",
      "****************************************************************************************************\n",
      "Epoch----->144 .. LR: 0.005 .. KL_theta: 8916.27 .. KL_eta: 267.84 .. KL_alpha: 838913.67 .. Rec_loss: 30918364.71 .. NELBO: 31766462.47\n",
      "****************************************************************************************************\n",
      "Epoch: 145 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8897.54 .. KL_eta: 276.05 .. KL_alpha: 840283.39 .. Rec_loss: 31083946.36 .. NELBO: 31933403.45\n",
      "****************************************************************************************************\n",
      "Epoch----->145 .. LR: 0.005 .. KL_theta: 8859.84 .. KL_eta: 287.18 .. KL_alpha: 837970.59 .. Rec_loss: 30993344.12 .. NELBO: 31840461.65\n",
      "****************************************************************************************************\n",
      "Epoch: 146 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9131.36 .. KL_eta: 263.61 .. KL_alpha: 825666.63 .. Rec_loss: 31005654.91 .. NELBO: 31840716.55\n",
      "****************************************************************************************************\n",
      "Epoch----->146 .. LR: 0.005 .. KL_theta: 8869.44 .. KL_eta: 259.46 .. KL_alpha: 825014.41 .. Rec_loss: 30872100.0 .. NELBO: 31706243.18\n",
      "****************************************************************************************************\n",
      "Epoch: 147 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8921.3 .. KL_eta: 314.72 .. KL_alpha: 818249.27 .. Rec_loss: 31240138.55 .. NELBO: 32067623.82\n",
      "****************************************************************************************************\n",
      "Epoch----->147 .. LR: 0.005 .. KL_theta: 8887.59 .. KL_eta: 303.16 .. KL_alpha: 817981.56 .. Rec_loss: 30982979.76 .. NELBO: 31810151.88\n",
      "****************************************************************************************************\n",
      "Epoch: 148 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8851.44 .. KL_eta: 257.14 .. KL_alpha: 812517.4 .. Rec_loss: 30893946.18 .. NELBO: 31715571.82\n",
      "****************************************************************************************************\n",
      "Epoch----->148 .. LR: 0.005 .. KL_theta: 9075.02 .. KL_eta: 262.1 .. KL_alpha: 813145.85 .. Rec_loss: 31012594.94 .. NELBO: 31835078.0\n",
      "****************************************************************************************************\n",
      "Epoch: 149 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9096.57 .. KL_eta: 271.7 .. KL_alpha: 805423.32 .. Rec_loss: 31075170.36 .. NELBO: 31889962.36\n",
      "****************************************************************************************************\n",
      "Epoch----->149 .. LR: 0.005 .. KL_theta: 9058.92 .. KL_eta: 274.23 .. KL_alpha: 802858.82 .. Rec_loss: 31180109.06 .. NELBO: 31992301.29\n",
      "****************************************************************************************************\n",
      "saving topic matrix beta...\n",
      "CPU times: user 17h 8min 13s, sys: 33min 32s, total: 17h 41min 45s\n",
      "Wall time: 22min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train model on data by looping through multiple epochs\n",
    "best_epoch = 0\n",
    "best_val_ppl = 1e9\n",
    "all_val_ppls = []\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(\n",
    "        epoch,\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_tokens, \n",
    "        train_counts, \n",
    "        train_times, \n",
    "        train_rnn_inp,\n",
    "        args\n",
    "    )\n",
    "    ## check whether to anneal lr\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if args.anneal_lr and (len(all_val_ppls) > args.nonmono and val_ppl > min(all_val_ppls[:-args.nonmono]) and lr > 1e-5):\n",
    "        optimizer.param_groups[0]['lr'] /= args.lr_factor\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('saving topic matrix beta...')\n",
    "    alpha = model.mu_q_alpha\n",
    "    beta = model.get_beta(alpha).cpu().numpy()\n",
    "    scipy.io.savemat(ckpt+'_beta.mat', {'values': beta}, do_compression=True)\n",
    "    if args.train_embeddings:\n",
    "        print('saving word embedding matrix rho...')\n",
    "        rho = model.rho.weight.cpu().numpy()\n",
    "        scipy.io.savemat(ckpt+'_rho.mat', {'values': rho}, do_compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4597239-035a-4212-8a72-224f0c7777d8",
   "metadata": {},
   "source": [
    "## topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61bd0334-017d-4249-b74d-04ecce12839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary([vocab])\n",
    "df = pd.read_parquet('data/combined_clean.parquet')\n",
    "split_text = df['filtered_text'].str.split().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a5caa3-64aa-48c6-893e-2e50d23a1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:  torch.Size([10, 4, 4938])\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0 .. Time: 0 ===> ['vol', 'zone', 'expenditure', 'expect', 'expectancy', 'expectation', 'expected', 'expedite', 'expeditiously']\n",
      "Topic 0 .. Time: 2 ===> ['price', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite', 'expeditiously']\n",
      "Topic 1 .. Time: 0 ===> ['lender', 'zone', 'expeditiously', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected']\n",
      "Topic 1 .. Time: 2 ===> ['firm', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 2 .. Time: 0 ===> ['output', 'zone', 'expend', 'expect', 'expectancy', 'expectation', 'expected', 'expedite', 'expeditiously']\n",
      "Topic 2 .. Time: 2 ===> ['effect', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 3 .. Time: 0 ===> ['measure', 'zone', 'expedite', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected']\n",
      "Topic 3 .. Time: 2 ===> ['inflation', 'zone', 'expeditiously', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected']\n",
      "Topic 4 .. Time: 0 ===> ['asset', 'expeditiously', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 4 .. Time: 2 ===> ['asset', 'expeditiously', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 5 .. Time: 0 ===> ['demand', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite', 'expeditiously']\n",
      "Topic 5 .. Time: 2 ===> ['condition', 'expeditiously', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 6 .. Time: 0 ===> ['derivative', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 6 .. Time: 2 ===> ['derivative', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 7 .. Time: 0 ===> ['bank', 'zone', 'expeditiously', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 7 .. Time: 2 ===> ['bank', 'zone', 'expeditiously', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 8 .. Time: 0 ===> ['effect', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n",
      "Topic 8 .. Time: 2 ===> ['run', 'expedite', 'expansion', 'expansionary', 'expansive', 'expect', 'expectancy', 'expectation', 'expected']\n",
      "Topic 9 .. Time: 0 ===> ['force', 'zone', 'expenditure', 'expect', 'expectancy', 'expectation', 'expected', 'expedite', 'expeditiously']\n",
      "Topic 9 .. Time: 2 ===> ['rate', 'zone', 'expend', 'expansive', 'expect', 'expectancy', 'expectation', 'expected', 'expedite']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    alpha = model.mu_q_alpha\n",
    "    beta = model.get_beta(alpha) \n",
    "    print('beta: ', beta.size())\n",
    "    print('\\n')\n",
    "    print('#'*100)\n",
    "    print('Visualize topics...')\n",
    "    times = [0, 2]\n",
    "    topics_words = []\n",
    "    for k in range(args.num_topics):\n",
    "        for t in times:\n",
    "            gamma = beta[k, t, :]\n",
    "            top_words = list(gamma.cpu().numpy().argsort()[-args.num_words+1:][::-1])\n",
    "            topic_words = [id2word[a] for a in top_words]\n",
    "            topics_words.append(' '.join(topic_words))\n",
    "            print('Topic {} .. Time: {} ===> {}'.format(k, t, topic_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875cc2f5-a7c3-40d7-99fa-009615a681fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:31<00:00,  7.97s/it]\n"
     ]
    }
   ],
   "source": [
    "coherences = []\n",
    "for t in tqdm(range(args.num_times)):\n",
    "    coherences.append(\n",
    "        CoherenceModel(\n",
    "            topics=get_detm_topics(beta=beta, time=t, num_words=20, vocab=id2word, num_topics=args.num_topics), # use 20 words to standardize with DTM\n",
    "            texts=split_text, \n",
    "            dictionary=id2word, \n",
    "            coherence='c_v'\n",
    "        ).get_coherence()\n",
    "    )\n",
    "\n",
    "coherences = np.array(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6974375b-7d95-4791-86df-38bff566cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 1119.38it/s]\n"
     ]
    }
   ],
   "source": [
    "diversities = []\n",
    "for t in tqdm(range(args.num_times)):\n",
    "    diversities.append(\n",
    "        topic_diversity(topics=get_detm_topics(beta=beta, time=t, num_words=20, vocab=id2word, num_topics=args.num_topics))\n",
    "    )\n",
    "    \n",
    "diversities = np.array(diversities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f594329e-4180-456a-973e-274a8d7be83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06458890963656823, 0.0004048561895348653)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualities = diversities * coherences\n",
    "qualities.mean(), qualities.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e305e433-b11e-4017-acbd-c19f1e8dbe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.40640332, 0.40601115, 0.40115414, 0.40115414]),\n",
       " array([0.16, 0.16, 0.16, 0.16]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherences, diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938b798d-82c2-4eb9-811a-b80f465d2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    'detm_stats_t5_alt.npz',\n",
    "    coherence=coherences,\n",
    "    diversity=diversities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad185df5-d26e-4d62-8f50-8378a9beea49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
