{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b842b476-674e-4f7c-97ff-6573850ba701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/amarvenu/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from run import get_args, process_data, prep_files, get_model, train\n",
    "import torch\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm\n",
    "from analysis_utils import get_detm_topics, topic_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098ca3c1-40e0-4d72-a367-bce9f749b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data and file related arguments\n",
    "arg_str = \"\"\"\n",
    "parser.add_argument('--dataset', type=str, default='un', help='name of corpus')\n",
    "parser.add_argument('--data_path', type=str, default='un/', help='directory containing data')\n",
    "parser.add_argument('--emb_path', type=str, default='skipgram/embeddings.txt', help='directory containing embeddings')\n",
    "parser.add_argument('--save_path', type=str, default='./results', help='path to save results')\n",
    "parser.add_argument('--batch_size', type=int, default=1000, help='number of documents in a batch for training')\n",
    "parser.add_argument('--min_df', type=int, default=100, help='to get the right data..minimum document frequency')\n",
    "\n",
    "### model-related arguments\n",
    "parser.add_argument('--num_topics', type=int, default=50, help='number of topics')\n",
    "parser.add_argument('--rho_size', type=int, default=300, help='dimension of rho')\n",
    "parser.add_argument('--emb_size', type=int, default=300, help='dimension of embeddings')\n",
    "parser.add_argument('--t_hidden_size', type=int, default=800, help='dimension of hidden space of q(theta)')\n",
    "parser.add_argument('--theta_act', type=str, default='relu', help='tanh, softplus, relu, rrelu, leakyrelu, elu, selu, glu)')\n",
    "parser.add_argument('--train_embeddings', type=int, default=1, help='whether to fix rho or train it')\n",
    "parser.add_argument('--eta_nlayers', type=int, default=3, help='number of layers for eta')\n",
    "parser.add_argument('--eta_hidden_size', type=int, default=200, help='number of hidden units for rnn')\n",
    "parser.add_argument('--delta', type=float, default=0.005, help='prior variance')\n",
    "\n",
    "### optimization-related arguments\n",
    "parser.add_argument('--lr', type=float, default=0.005, help='learning rate')\n",
    "parser.add_argument('--lr_factor', type=float, default=4.0, help='divide learning rate by this')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train')\n",
    "parser.add_argument('--mode', type=str, default='train', help='train or eval model')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='choice of optimizer')\n",
    "parser.add_argument('--seed', type=int, default=2019, help='random seed (default: 1)')\n",
    "parser.add_argument('--enc_drop', type=float, default=0.0, help='dropout rate on encoder')\n",
    "parser.add_argument('--eta_dropout', type=float, default=0.0, help='dropout rate on rnn for eta')\n",
    "parser.add_argument('--clip', type=float, default=0.0, help='gradient clipping')\n",
    "parser.add_argument('--nonmono', type=int, default=10, help='number of bad hits allowed')\n",
    "parser.add_argument('--wdecay', type=float, default=1.2e-6, help='some l2 regularization')\n",
    "parser.add_argument('--anneal_lr', type=int, default=0, help='whether to anneal the learning rate or not')\n",
    "parser.add_argument('--bow_norm', type=int, default=1, help='normalize the bows or not')\n",
    "\n",
    "### evaluation, visualization, and logging-related arguments\n",
    "parser.add_argument('--num_words', type=int, default=20, help='number of words for topic viz')\n",
    "parser.add_argument('--log_interval', type=int, default=10, help='when to log training')\n",
    "parser.add_argument('--visualize_every', type=int, default=1, help='when to visualize results')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=1000, help='input batch size for evaluation')\n",
    "parser.add_argument('--load_from', type=str, default='', help='the name of the ckpt to eval from')\n",
    "parser.add_argument('--tc', type=int, default=0, help='whether to compute tc or not')\n",
    "\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbb0cf6-cb59-4c14-9d3f-7425c4cef152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495f46a1-bb2a-45a3-94e2-8e33eda49897",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [x.strip(\"parser.add_argument('\").split(',')[0].strip('--').strip(\"'\") for x in arg_str if (len(x) > 0) and (not x.startswith('#'))]\n",
    "values = [x.strip(\"parser.add_argument('\").split(',')[2].strip(\" default=\").strip(\"'\") for x in arg_str if (len(x) > 0) and (not x.startswith('#'))]\n",
    "tmp_dict = dict(zip(keys, values))\n",
    "\n",
    "for k, v in tmp_dict.items():\n",
    "    if v.isnumeric():\n",
    "        tmp_dict[k] = int(v)\n",
    "    elif ('.' in v) and (v[0].isnumeric()):\n",
    "        tmp_dict[k] = float(v)    \n",
    "\n",
    "args = AttrDict()\n",
    "args.update(tmp_dict)\n",
    "\n",
    "args.train_embeddings = 0\n",
    "args.num_topics = 10\n",
    "args.batch_size = 100\n",
    "args.epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5be51b-033c-4fc4-966f-fd47d89439a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0/2\n"
     ]
    }
   ],
   "source": [
    "train_rnn_inp, train_tokens, train_counts, train_times, vocab, embeddings, args = process_data(\n",
    "    file='test_data_glove.npz',\n",
    "    args=args\n",
    ")\n",
    "\n",
    "args.rho_size = embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e5a96e-0d0b-4ca3-8a36-e281c320caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = prep_files(args, 'glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34d57391-ae53-4c16-ad59-2687f61dd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, args = get_model(args, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e46ab345-d734-48d4-b63b-116e9514f638",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 6455.87 .. KL_eta: 2210.52 .. KL_alpha: 4596614.05 .. Rec_loss: 31871246.91 .. NELBO: 36476526.55\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 6244.14 .. KL_eta: 1502.6 .. KL_alpha: 4546031.62 .. Rec_loss: 31692327.53 .. NELBO: 36246105.41\n",
      "****************************************************************************************************\n",
      "Epoch: 2 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 8862.29 .. KL_eta: 137.9 .. KL_alpha: 4296428.34 .. Rec_loss: 31092908.73 .. NELBO: 35398337.27\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 8028.14 .. KL_eta: 135.28 .. KL_alpha: 4260052.24 .. Rec_loss: 31649762.24 .. NELBO: 35917977.53\n",
      "****************************************************************************************************\n",
      "Epoch: 3 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7421.06 .. KL_eta: 93.68 .. KL_alpha: 4067260.95 .. Rec_loss: 31488751.64 .. NELBO: 35563528.18\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 8704.91 .. KL_eta: 96.12 .. KL_alpha: 4041330.31 .. Rec_loss: 31615387.18 .. NELBO: 35665519.29\n",
      "****************************************************************************************************\n",
      "Epoch: 4 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 7988.02 .. KL_eta: 77.53 .. KL_alpha: 3872003.11 .. Rec_loss: 31213378.55 .. NELBO: 35093447.45\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 8210.15 .. KL_eta: 80.43 .. KL_alpha: 3851777.63 .. Rec_loss: 31508131.06 .. NELBO: 35368199.65\n",
      "****************************************************************************************************\n",
      "Epoch: 5 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 11719.55 .. KL_eta: 116.39 .. KL_alpha: 3690032.3 .. Rec_loss: 31735101.64 .. NELBO: 35436970.55\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 11099.79 .. KL_eta: 132.34 .. KL_alpha: 3669102.76 .. Rec_loss: 31339943.65 .. NELBO: 35020278.71\n",
      "****************************************************************************************************\n",
      "Epoch: 6 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 10243.41 .. KL_eta: 101.67 .. KL_alpha: 3543574.25 .. Rec_loss: 31049438.18 .. NELBO: 34603357.64\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 10955.64 .. KL_eta: 107.84 .. KL_alpha: 3511730.68 .. Rec_loss: 31359283.88 .. NELBO: 34882078.24\n",
      "****************************************************************************************************\n",
      "Epoch: 7 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 9602.1 .. KL_eta: 157.69 .. KL_alpha: 3388598.64 .. Rec_loss: 31580314.55 .. NELBO: 34978673.09\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 10963.18 .. KL_eta: 153.14 .. KL_alpha: 3363630.0 .. Rec_loss: 31144419.29 .. NELBO: 34519165.41\n",
      "****************************************************************************************************\n",
      "Epoch: 8 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 11452.09 .. KL_eta: 129.03 .. KL_alpha: 3294342.61 .. Rec_loss: 30790313.45 .. NELBO: 34096237.27\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 11858.95 .. KL_eta: 136.38 .. KL_alpha: 3256292.75 .. Rec_loss: 30959749.76 .. NELBO: 34228037.65\n",
      "****************************************************************************************************\n",
      "Epoch: 9 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 13248.12 .. KL_eta: 91.91 .. KL_alpha: 3157630.02 .. Rec_loss: 30922922.36 .. NELBO: 34093893.27\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 12795.34 .. KL_eta: 87.32 .. KL_alpha: 3136824.72 .. Rec_loss: 30730499.41 .. NELBO: 33880206.94\n",
      "****************************************************************************************************\n",
      "Epoch: 10 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 16354.15 .. KL_eta: 82.26 .. KL_alpha: 3059584.86 .. Rec_loss: 30437821.09 .. NELBO: 33513841.64\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 15782.43 .. KL_eta: 76.29 .. KL_alpha: 3043080.22 .. Rec_loss: 30643945.41 .. NELBO: 33702883.88\n",
      "****************************************************************************************************\n",
      "Epoch: 11 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 13556.89 .. KL_eta: 61.03 .. KL_alpha: 2960136.39 .. Rec_loss: 30122148.73 .. NELBO: 33095903.27\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 15070.94 .. KL_eta: 61.62 .. KL_alpha: 2951512.21 .. Rec_loss: 30403358.59 .. NELBO: 33370003.88\n",
      "****************************************************************************************************\n",
      "Epoch: 12 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 16714.64 .. KL_eta: 96.2 .. KL_alpha: 2860331.23 .. Rec_loss: 30093699.27 .. NELBO: 32970841.45\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 16470.12 .. KL_eta: 95.64 .. KL_alpha: 2842943.94 .. Rec_loss: 30195799.65 .. NELBO: 33055309.53\n",
      "****************************************************************************************************\n",
      "Epoch: 13 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 15318.26 .. KL_eta: 139.91 .. KL_alpha: 2781526.18 .. Rec_loss: 29913279.27 .. NELBO: 32710263.82\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 16337.26 .. KL_eta: 135.56 .. KL_alpha: 2769570.1 .. Rec_loss: 29898568.24 .. NELBO: 32684611.53\n",
      "****************************************************************************************************\n",
      "Epoch: 14 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 17455.42 .. KL_eta: 141.37 .. KL_alpha: 2703094.86 .. Rec_loss: 28999239.64 .. NELBO: 31719931.45\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 16935.08 .. KL_eta: 136.24 .. KL_alpha: 2695882.68 .. Rec_loss: 29945243.41 .. NELBO: 32658197.76\n",
      "****************************************************************************************************\n",
      "Epoch: 15 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 16327.52 .. KL_eta: 119.84 .. KL_alpha: 2624478.48 .. Rec_loss: 29679290.18 .. NELBO: 32320215.64\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 16831.89 .. KL_eta: 111.33 .. KL_alpha: 2619888.18 .. Rec_loss: 29822373.88 .. NELBO: 32459204.94\n",
      "****************************************************************************************************\n",
      "Epoch: 16 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 17183.33 .. KL_eta: 108.41 .. KL_alpha: 2568390.8 .. Rec_loss: 29218061.82 .. NELBO: 31803744.36\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 16922.19 .. KL_eta: 124.56 .. KL_alpha: 2558101.04 .. Rec_loss: 29502820.35 .. NELBO: 32077968.12\n",
      "****************************************************************************************************\n",
      "Epoch: 17 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 17752.78 .. KL_eta: 157.4 .. KL_alpha: 2501670.68 .. Rec_loss: 29246534.91 .. NELBO: 31766115.82\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 17305.24 .. KL_eta: 171.14 .. KL_alpha: 2484913.88 .. Rec_loss: 29245874.82 .. NELBO: 31748265.41\n",
      "****************************************************************************************************\n",
      "Epoch: 18 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 17681.96 .. KL_eta: 261.8 .. KL_alpha: 2434447.0 .. Rec_loss: 29456726.73 .. NELBO: 31909118.18\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 19326.81 .. KL_eta: 216.39 .. KL_alpha: 2423340.84 .. Rec_loss: 29000199.76 .. NELBO: 31443084.35\n",
      "****************************************************************************************************\n",
      "Epoch: 19 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 17982.13 .. KL_eta: 116.22 .. KL_alpha: 2366525.32 .. Rec_loss: 29253549.82 .. NELBO: 31638174.0\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 18870.88 .. KL_eta: 128.26 .. KL_alpha: 2355325.44 .. Rec_loss: 28833900.71 .. NELBO: 31208225.53\n",
      "****************************************************************************************************\n",
      "Epoch: 20 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 18752.19 .. KL_eta: 165.78 .. KL_alpha: 2328746.18 .. Rec_loss: 28830270.18 .. NELBO: 31177933.45\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 19135.02 .. KL_eta: 176.11 .. KL_alpha: 2312910.46 .. Rec_loss: 28942215.29 .. NELBO: 31274436.47\n",
      "****************************************************************************************************\n",
      "Epoch: 21 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 21346.8 .. KL_eta: 223.77 .. KL_alpha: 2278944.02 .. Rec_loss: 28653619.09 .. NELBO: 30954134.0\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 21062.59 .. KL_eta: 249.62 .. KL_alpha: 2269510.88 .. Rec_loss: 28574675.53 .. NELBO: 30865498.71\n",
      "****************************************************************************************************\n",
      "Epoch: 22 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 22083.88 .. KL_eta: 328.77 .. KL_alpha: 2208708.16 .. Rec_loss: 28471426.91 .. NELBO: 30702548.18\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 21713.27 .. KL_eta: 387.26 .. KL_alpha: 2208748.88 .. Rec_loss: 28535676.71 .. NELBO: 30766526.24\n",
      "****************************************************************************************************\n",
      "Epoch: 23 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 21783.22 .. KL_eta: 640.0 .. KL_alpha: 2166707.61 .. Rec_loss: 28318218.73 .. NELBO: 30507349.45\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 21548.89 .. KL_eta: 603.49 .. KL_alpha: 2155793.94 .. Rec_loss: 28219842.82 .. NELBO: 30397788.94\n",
      "****************************************************************************************************\n",
      "Epoch: 24 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 19798.68 .. KL_eta: 268.77 .. KL_alpha: 2119686.36 .. Rec_loss: 28690135.09 .. NELBO: 30829888.91\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 22001.47 .. KL_eta: 389.18 .. KL_alpha: 2112928.8 .. Rec_loss: 28231721.41 .. NELBO: 30367040.94\n",
      "****************************************************************************************************\n",
      "Epoch: 25 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 22694.11 .. KL_eta: 761.22 .. KL_alpha: 2081081.35 .. Rec_loss: 27955235.09 .. NELBO: 30059771.45\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 23406.36 .. KL_eta: 685.61 .. KL_alpha: 2070792.36 .. Rec_loss: 28129871.29 .. NELBO: 30224755.29\n",
      "****************************************************************************************************\n",
      "Epoch: 26 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 19855.07 .. KL_eta: 382.7 .. KL_alpha: 2044971.64 .. Rec_loss: 28204883.64 .. NELBO: 30270092.73\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 22005.8 .. KL_eta: 445.71 .. KL_alpha: 2034075.49 .. Rec_loss: 27959785.29 .. NELBO: 30016312.24\n",
      "****************************************************************************************************\n",
      "Epoch: 27 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25058.38 .. KL_eta: 441.19 .. KL_alpha: 1987406.82 .. Rec_loss: 27767129.09 .. NELBO: 29780035.82\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 23991.36 .. KL_eta: 461.22 .. KL_alpha: 1978879.76 .. Rec_loss: 27795866.82 .. NELBO: 29799199.18\n",
      "****************************************************************************************************\n",
      "Epoch: 28 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 22389.42 .. KL_eta: 566.49 .. KL_alpha: 1938811.92 .. Rec_loss: 27174209.82 .. NELBO: 29135977.64\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 22297.7 .. KL_eta: 536.71 .. KL_alpha: 1932359.81 .. Rec_loss: 27610138.35 .. NELBO: 29565332.47\n",
      "****************************************************************************************************\n",
      "Epoch: 29 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 22844.8 .. KL_eta: 621.61 .. KL_alpha: 1905563.24 .. Rec_loss: 27551079.09 .. NELBO: 29480108.91\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 23267.28 .. KL_eta: 578.26 .. KL_alpha: 1901632.62 .. Rec_loss: 27612658.59 .. NELBO: 29538136.94\n",
      "****************************************************************************************************\n",
      "Epoch: 30 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 23835.75 .. KL_eta: 558.26 .. KL_alpha: 1867071.68 .. Rec_loss: 27351517.64 .. NELBO: 29242982.73\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 23101.9 .. KL_eta: 524.46 .. KL_alpha: 1858720.64 .. Rec_loss: 27152318.59 .. NELBO: 29034665.29\n",
      "****************************************************************************************************\n",
      "Epoch: 31 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25310.43 .. KL_eta: 721.6 .. KL_alpha: 1835910.01 .. Rec_loss: 27356529.09 .. NELBO: 29218471.64\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 25234.12 .. KL_eta: 656.04 .. KL_alpha: 1829009.71 .. Rec_loss: 27246682.12 .. NELBO: 29101582.35\n",
      "****************************************************************************************************\n",
      "Epoch: 32 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27554.36 .. KL_eta: 720.23 .. KL_alpha: 1803348.64 .. Rec_loss: 27187666.55 .. NELBO: 29019289.82\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 25719.44 .. KL_eta: 707.79 .. KL_alpha: 1797579.79 .. Rec_loss: 27056374.71 .. NELBO: 28880381.76\n",
      "****************************************************************************************************\n",
      "Epoch: 33 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 23559.08 .. KL_eta: 489.34 .. KL_alpha: 1773354.83 .. Rec_loss: 26739368.0 .. NELBO: 28536771.27\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 23955.51 .. KL_eta: 472.38 .. KL_alpha: 1763103.56 .. Rec_loss: 26998780.94 .. NELBO: 28786312.35\n",
      "****************************************************************************************************\n",
      "Epoch: 34 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 22421.44 .. KL_eta: 611.06 .. KL_alpha: 1731327.47 .. Rec_loss: 26930474.91 .. NELBO: 28684835.09\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 24144.05 .. KL_eta: 596.43 .. KL_alpha: 1726134.4 .. Rec_loss: 26794034.24 .. NELBO: 28544909.29\n",
      "****************************************************************************************************\n",
      "Epoch: 35 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26029.52 .. KL_eta: 506.63 .. KL_alpha: 1708831.01 .. Rec_loss: 26999718.91 .. NELBO: 28735086.0\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 25699.18 .. KL_eta: 474.42 .. KL_alpha: 1704175.25 .. Rec_loss: 26652786.12 .. NELBO: 28383135.29\n",
      "****************************************************************************************************\n",
      "Epoch: 36 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25596.5 .. KL_eta: 423.12 .. KL_alpha: 1663712.65 .. Rec_loss: 26269580.36 .. NELBO: 27959313.27\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 25177.53 .. KL_eta: 467.49 .. KL_alpha: 1661002.5 .. Rec_loss: 26489055.88 .. NELBO: 28175703.88\n",
      "****************************************************************************************************\n",
      "Epoch: 37 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25181.78 .. KL_eta: 626.59 .. KL_alpha: 1629784.06 .. Rec_loss: 26193440.0 .. NELBO: 27849032.18\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 26416.17 .. KL_eta: 701.17 .. KL_alpha: 1624853.71 .. Rec_loss: 26540630.24 .. NELBO: 28192601.29\n",
      "****************************************************************************************************\n",
      "Epoch: 38 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27477.02 .. KL_eta: 633.93 .. KL_alpha: 1606070.45 .. Rec_loss: 26270698.55 .. NELBO: 27904880.0\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 25276.77 .. KL_eta: 558.01 .. KL_alpha: 1604177.71 .. Rec_loss: 26279405.18 .. NELBO: 27909417.65\n",
      "****************************************************************************************************\n",
      "Epoch: 39 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25365.62 .. KL_eta: 763.08 .. KL_alpha: 1572156.23 .. Rec_loss: 25993434.73 .. NELBO: 27591720.18\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 25171.79 .. KL_eta: 768.78 .. KL_alpha: 1571404.2 .. Rec_loss: 26332372.47 .. NELBO: 27929717.65\n",
      "****************************************************************************************************\n",
      "Epoch: 40 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27349.19 .. KL_eta: 503.62 .. KL_alpha: 1550658.38 .. Rec_loss: 25547651.82 .. NELBO: 27126163.64\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 27160.24 .. KL_eta: 470.36 .. KL_alpha: 1542164.18 .. Rec_loss: 26030314.12 .. NELBO: 27600109.29\n",
      "****************************************************************************************************\n",
      "Epoch: 41 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 24593.89 .. KL_eta: 358.09 .. KL_alpha: 1516382.25 .. Rec_loss: 26191921.64 .. NELBO: 27733256.55\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 26106.27 .. KL_eta: 367.25 .. KL_alpha: 1518661.96 .. Rec_loss: 26157935.65 .. NELBO: 27703071.41\n",
      "****************************************************************************************************\n",
      "Epoch: 42 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28040.37 .. KL_eta: 379.3 .. KL_alpha: 1498229.81 .. Rec_loss: 26244825.82 .. NELBO: 27771474.91\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 26563.3 .. KL_eta: 408.43 .. KL_alpha: 1489442.14 .. Rec_loss: 25811231.06 .. NELBO: 27327644.47\n",
      "****************************************************************************************************\n",
      "Epoch: 43 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 24907.01 .. KL_eta: 603.76 .. KL_alpha: 1475916.08 .. Rec_loss: 25641453.27 .. NELBO: 27142880.18\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 25683.49 .. KL_eta: 573.11 .. KL_alpha: 1468294.57 .. Rec_loss: 25803042.94 .. NELBO: 27297594.24\n",
      "****************************************************************************************************\n",
      "Epoch: 44 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28024.81 .. KL_eta: 541.62 .. KL_alpha: 1435799.4 .. Rec_loss: 26148299.27 .. NELBO: 27612664.91\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 26543.18 .. KL_eta: 504.78 .. KL_alpha: 1438323.55 .. Rec_loss: 25730198.94 .. NELBO: 27195570.24\n",
      "****************************************************************************************************\n",
      "Epoch: 45 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27760.73 .. KL_eta: 357.44 .. KL_alpha: 1422913.02 .. Rec_loss: 25998145.09 .. NELBO: 27449176.36\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 28772.38 .. KL_eta: 408.26 .. KL_alpha: 1413240.06 .. Rec_loss: 25350867.76 .. NELBO: 26793288.35\n",
      "****************************************************************************************************\n",
      "Epoch: 46 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26659.0 .. KL_eta: 511.08 .. KL_alpha: 1400397.62 .. Rec_loss: 25091867.09 .. NELBO: 26519434.55\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 26615.65 .. KL_eta: 547.27 .. KL_alpha: 1395774.02 .. Rec_loss: 25482911.88 .. NELBO: 26905848.82\n",
      "****************************************************************************************************\n",
      "Epoch: 47 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25393.47 .. KL_eta: 433.11 .. KL_alpha: 1373761.74 .. Rec_loss: 25431582.18 .. NELBO: 26831170.18\n",
      "****************************************************************************************************\n",
      "Epoch----->47 .. LR: 0.005 .. KL_theta: 25402.45 .. KL_eta: 432.49 .. KL_alpha: 1369782.08 .. Rec_loss: 25474592.12 .. NELBO: 26870209.06\n",
      "****************************************************************************************************\n",
      "Epoch: 48 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 24873.57 .. KL_eta: 447.26 .. KL_alpha: 1347328.44 .. Rec_loss: 25496539.09 .. NELBO: 26869188.55\n",
      "****************************************************************************************************\n",
      "Epoch----->48 .. LR: 0.005 .. KL_theta: 25550.58 .. KL_eta: 443.22 .. KL_alpha: 1340950.82 .. Rec_loss: 25413064.35 .. NELBO: 26780009.06\n",
      "****************************************************************************************************\n",
      "Epoch: 49 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26845.54 .. KL_eta: 450.23 .. KL_alpha: 1323280.02 .. Rec_loss: 25196748.36 .. NELBO: 26547324.55\n",
      "****************************************************************************************************\n",
      "Epoch----->49 .. LR: 0.005 .. KL_theta: 27819.95 .. KL_eta: 422.37 .. KL_alpha: 1323501.88 .. Rec_loss: 25279105.06 .. NELBO: 26630849.41\n",
      "****************************************************************************************************\n",
      "Epoch: 50 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28177.01 .. KL_eta: 439.07 .. KL_alpha: 1306559.48 .. Rec_loss: 24942563.45 .. NELBO: 26277739.09\n",
      "****************************************************************************************************\n",
      "Epoch----->50 .. LR: 0.005 .. KL_theta: 27054.12 .. KL_eta: 525.75 .. KL_alpha: 1301551.22 .. Rec_loss: 25201230.94 .. NELBO: 26530362.24\n",
      "****************************************************************************************************\n",
      "Epoch: 51 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26600.25 .. KL_eta: 569.5 .. KL_alpha: 1285575.99 .. Rec_loss: 25216389.64 .. NELBO: 26529135.27\n",
      "****************************************************************************************************\n",
      "Epoch----->51 .. LR: 0.005 .. KL_theta: 26672.57 .. KL_eta: 501.2 .. KL_alpha: 1280718.9 .. Rec_loss: 25040237.76 .. NELBO: 26348130.47\n",
      "****************************************************************************************************\n",
      "Epoch: 52 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30022.14 .. KL_eta: 371.03 .. KL_alpha: 1258579.75 .. Rec_loss: 25250802.91 .. NELBO: 26539776.0\n",
      "****************************************************************************************************\n",
      "Epoch----->52 .. LR: 0.005 .. KL_theta: 28564.54 .. KL_eta: 376.36 .. KL_alpha: 1256827.12 .. Rec_loss: 25041533.88 .. NELBO: 26327302.12\n",
      "****************************************************************************************************\n",
      "Epoch: 53 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29132.37 .. KL_eta: 486.14 .. KL_alpha: 1239363.97 .. Rec_loss: 24728583.64 .. NELBO: 25997565.64\n",
      "****************************************************************************************************\n",
      "Epoch----->53 .. LR: 0.005 .. KL_theta: 28050.15 .. KL_eta: 476.39 .. KL_alpha: 1235253.32 .. Rec_loss: 24872258.35 .. NELBO: 26136037.76\n",
      "****************************************************************************************************\n",
      "Epoch: 54 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 24777.0 .. KL_eta: 417.83 .. KL_alpha: 1222570.98 .. Rec_loss: 24661285.27 .. NELBO: 25909051.45\n",
      "****************************************************************************************************\n",
      "Epoch----->54 .. LR: 0.005 .. KL_theta: 25566.0 .. KL_eta: 417.82 .. KL_alpha: 1217564.12 .. Rec_loss: 24829564.24 .. NELBO: 26073112.24\n",
      "****************************************************************************************************\n",
      "Epoch: 55 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28400.22 .. KL_eta: 516.05 .. KL_alpha: 1206746.56 .. Rec_loss: 24746397.27 .. NELBO: 25982060.18\n",
      "****************************************************************************************************\n",
      "Epoch----->55 .. LR: 0.005 .. KL_theta: 27440.12 .. KL_eta: 476.48 .. KL_alpha: 1204525.85 .. Rec_loss: 24657267.18 .. NELBO: 25889709.53\n",
      "****************************************************************************************************\n",
      "Epoch: 56 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27019.66 .. KL_eta: 274.91 .. KL_alpha: 1189831.98 .. Rec_loss: 24703598.36 .. NELBO: 25920725.09\n",
      "****************************************************************************************************\n",
      "Epoch----->56 .. LR: 0.005 .. KL_theta: 27511.1 .. KL_eta: 299.3 .. KL_alpha: 1185242.61 .. Rec_loss: 24644403.41 .. NELBO: 25857456.59\n",
      "****************************************************************************************************\n",
      "Epoch: 57 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27630.19 .. KL_eta: 655.21 .. KL_alpha: 1165894.44 .. Rec_loss: 24365458.36 .. NELBO: 25559638.0\n",
      "****************************************************************************************************\n",
      "Epoch----->57 .. LR: 0.005 .. KL_theta: 26665.98 .. KL_eta: 652.52 .. KL_alpha: 1160751.12 .. Rec_loss: 24476006.47 .. NELBO: 25664076.0\n",
      "****************************************************************************************************\n",
      "Epoch: 58 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27619.86 .. KL_eta: 601.42 .. KL_alpha: 1151050.06 .. Rec_loss: 24181728.18 .. NELBO: 25360999.64\n",
      "****************************************************************************************************\n",
      "Epoch----->58 .. LR: 0.005 .. KL_theta: 28049.08 .. KL_eta: 583.5 .. KL_alpha: 1146680.15 .. Rec_loss: 24392676.24 .. NELBO: 25567989.06\n",
      "****************************************************************************************************\n",
      "Epoch: 59 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29739.9 .. KL_eta: 559.12 .. KL_alpha: 1137183.16 .. Rec_loss: 24331224.18 .. NELBO: 25498706.73\n",
      "****************************************************************************************************\n",
      "Epoch----->59 .. LR: 0.005 .. KL_theta: 28764.08 .. KL_eta: 515.52 .. KL_alpha: 1134800.31 .. Rec_loss: 24319558.0 .. NELBO: 25483637.88\n",
      "****************************************************************************************************\n",
      "Epoch: 60 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28349.78 .. KL_eta: 409.04 .. KL_alpha: 1113842.9 .. Rec_loss: 24636606.0 .. NELBO: 25779208.36\n",
      "****************************************************************************************************\n",
      "Epoch----->60 .. LR: 0.005 .. KL_theta: 27815.84 .. KL_eta: 402.91 .. KL_alpha: 1111286.71 .. Rec_loss: 24365216.94 .. NELBO: 25504722.71\n",
      "****************************************************************************************************\n",
      "Epoch: 61 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28445.31 .. KL_eta: 387.74 .. KL_alpha: 1088528.27 .. Rec_loss: 24348648.91 .. NELBO: 25466010.18\n",
      "****************************************************************************************************\n",
      "Epoch----->61 .. LR: 0.005 .. KL_theta: 28983.1 .. KL_eta: 401.62 .. KL_alpha: 1090322.3 .. Rec_loss: 24120687.18 .. NELBO: 25240394.0\n",
      "****************************************************************************************************\n",
      "Epoch: 62 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26891.12 .. KL_eta: 388.07 .. KL_alpha: 1075116.02 .. Rec_loss: 24158097.09 .. NELBO: 25260492.36\n",
      "****************************************************************************************************\n",
      "Epoch----->62 .. LR: 0.005 .. KL_theta: 27062.19 .. KL_eta: 419.8 .. KL_alpha: 1070891.59 .. Rec_loss: 24079928.35 .. NELBO: 25178302.12\n",
      "****************************************************************************************************\n",
      "Epoch: 63 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26705.84 .. KL_eta: 400.25 .. KL_alpha: 1060334.39 .. Rec_loss: 24395953.64 .. NELBO: 25483394.55\n",
      "****************************************************************************************************\n",
      "Epoch----->63 .. LR: 0.005 .. KL_theta: 27928.81 .. KL_eta: 433.81 .. KL_alpha: 1059374.31 .. Rec_loss: 24187182.12 .. NELBO: 25274919.06\n",
      "****************************************************************************************************\n",
      "Epoch: 64 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25299.86 .. KL_eta: 473.83 .. KL_alpha: 1038317.15 .. Rec_loss: 24072189.45 .. NELBO: 25136280.18\n",
      "****************************************************************************************************\n",
      "Epoch----->64 .. LR: 0.005 .. KL_theta: 25182.74 .. KL_eta: 454.43 .. KL_alpha: 1037900.49 .. Rec_loss: 23856508.59 .. NELBO: 24920046.47\n",
      "****************************************************************************************************\n",
      "Epoch: 65 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26015.55 .. KL_eta: 465.25 .. KL_alpha: 1030965.41 .. Rec_loss: 23745620.91 .. NELBO: 24803067.09\n",
      "****************************************************************************************************\n",
      "Epoch----->65 .. LR: 0.005 .. KL_theta: 27259.5 .. KL_eta: 448.12 .. KL_alpha: 1027612.96 .. Rec_loss: 23972990.47 .. NELBO: 25028310.94\n",
      "****************************************************************************************************\n",
      "Epoch: 66 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29169.87 .. KL_eta: 398.54 .. KL_alpha: 1012494.11 .. Rec_loss: 23907563.27 .. NELBO: 24949625.82\n",
      "****************************************************************************************************\n",
      "Epoch----->66 .. LR: 0.005 .. KL_theta: 29238.05 .. KL_eta: 431.15 .. KL_alpha: 1011039.57 .. Rec_loss: 23808644.12 .. NELBO: 24849352.94\n",
      "****************************************************************************************************\n",
      "Epoch: 67 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30004.67 .. KL_eta: 546.48 .. KL_alpha: 1005245.8 .. Rec_loss: 23481224.91 .. NELBO: 24517021.64\n",
      "****************************************************************************************************\n",
      "Epoch----->67 .. LR: 0.005 .. KL_theta: 28807.5 .. KL_eta: 559.83 .. KL_alpha: 1003447.23 .. Rec_loss: 23587754.0 .. NELBO: 24620568.35\n",
      "****************************************************************************************************\n",
      "Epoch: 68 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27172.09 .. KL_eta: 571.64 .. KL_alpha: 985942.55 .. Rec_loss: 23862152.36 .. NELBO: 24875838.73\n",
      "****************************************************************************************************\n",
      "Epoch----->68 .. LR: 0.005 .. KL_theta: 26950.37 .. KL_eta: 523.08 .. KL_alpha: 988555.12 .. Rec_loss: 23637222.47 .. NELBO: 24653251.06\n",
      "****************************************************************************************************\n",
      "Epoch: 69 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28126.0 .. KL_eta: 401.72 .. KL_alpha: 973516.79 .. Rec_loss: 23595295.45 .. NELBO: 24597339.82\n",
      "****************************************************************************************************\n",
      "Epoch----->69 .. LR: 0.005 .. KL_theta: 28634.62 .. KL_eta: 419.76 .. KL_alpha: 973724.21 .. Rec_loss: 23411587.53 .. NELBO: 24414366.24\n",
      "****************************************************************************************************\n",
      "Epoch: 70 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28083.83 .. KL_eta: 463.22 .. KL_alpha: 959242.59 .. Rec_loss: 23472232.73 .. NELBO: 24460022.55\n",
      "****************************************************************************************************\n",
      "Epoch----->70 .. LR: 0.005 .. KL_theta: 27440.39 .. KL_eta: 453.94 .. KL_alpha: 957008.67 .. Rec_loss: 23392366.35 .. NELBO: 24377269.53\n",
      "****************************************************************************************************\n",
      "Epoch: 71 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26617.67 .. KL_eta: 416.63 .. KL_alpha: 941729.55 .. Rec_loss: 23413486.91 .. NELBO: 24382250.55\n",
      "****************************************************************************************************\n",
      "Epoch----->71 .. LR: 0.005 .. KL_theta: 27426.73 .. KL_eta: 426.28 .. KL_alpha: 942091.44 .. Rec_loss: 23340961.41 .. NELBO: 24310905.88\n",
      "****************************************************************************************************\n",
      "Epoch: 72 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26320.65 .. KL_eta: 404.15 .. KL_alpha: 928723.89 .. Rec_loss: 23349171.64 .. NELBO: 24304620.36\n",
      "****************************************************************************************************\n",
      "Epoch----->72 .. LR: 0.005 .. KL_theta: 26075.03 .. KL_eta: 388.68 .. KL_alpha: 927318.15 .. Rec_loss: 23203547.88 .. NELBO: 24157330.0\n",
      "****************************************************************************************************\n",
      "Epoch: 73 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 31790.35 .. KL_eta: 521.25 .. KL_alpha: 916672.41 .. Rec_loss: 22670878.36 .. NELBO: 23619862.18\n",
      "****************************************************************************************************\n",
      "Epoch----->73 .. LR: 0.005 .. KL_theta: 29804.23 .. KL_eta: 493.3 .. KL_alpha: 910648.21 .. Rec_loss: 23079265.18 .. NELBO: 24020210.94\n",
      "****************************************************************************************************\n",
      "Epoch: 74 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27711.17 .. KL_eta: 379.95 .. KL_alpha: 905403.91 .. Rec_loss: 23278238.91 .. NELBO: 24211733.45\n",
      "****************************************************************************************************\n",
      "Epoch----->74 .. LR: 0.005 .. KL_theta: 27878.53 .. KL_eta: 385.47 .. KL_alpha: 901372.14 .. Rec_loss: 23166312.12 .. NELBO: 24095947.88\n",
      "****************************************************************************************************\n",
      "Epoch: 75 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29447.69 .. KL_eta: 414.16 .. KL_alpha: 893176.34 .. Rec_loss: 22925588.73 .. NELBO: 23848626.91\n",
      "****************************************************************************************************\n",
      "Epoch----->75 .. LR: 0.005 .. KL_theta: 29159.83 .. KL_eta: 405.53 .. KL_alpha: 888894.28 .. Rec_loss: 23128878.59 .. NELBO: 24047338.24\n",
      "****************************************************************************************************\n",
      "Epoch: 76 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27173.75 .. KL_eta: 421.08 .. KL_alpha: 883630.76 .. Rec_loss: 22861512.36 .. NELBO: 23772737.82\n",
      "****************************************************************************************************\n",
      "Epoch----->76 .. LR: 0.005 .. KL_theta: 26918.53 .. KL_eta: 418.34 .. KL_alpha: 876521.93 .. Rec_loss: 23027702.59 .. NELBO: 23931561.18\n",
      "****************************************************************************************************\n",
      "Epoch: 77 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26783.67 .. KL_eta: 459.86 .. KL_alpha: 868564.62 .. Rec_loss: 22972389.09 .. NELBO: 23868197.45\n",
      "****************************************************************************************************\n",
      "Epoch----->77 .. LR: 0.005 .. KL_theta: 26502.46 .. KL_eta: 469.48 .. KL_alpha: 865738.16 .. Rec_loss: 22916304.24 .. NELBO: 23809014.71\n",
      "****************************************************************************************************\n",
      "Epoch: 78 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28111.26 .. KL_eta: 451.58 .. KL_alpha: 853349.62 .. Rec_loss: 22619170.91 .. NELBO: 23501083.09\n",
      "****************************************************************************************************\n",
      "Epoch----->78 .. LR: 0.005 .. KL_theta: 28882.89 .. KL_eta: 439.69 .. KL_alpha: 853348.51 .. Rec_loss: 22727030.82 .. NELBO: 23609701.76\n",
      "****************************************************************************************************\n",
      "Epoch: 79 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30001.66 .. KL_eta: 409.47 .. KL_alpha: 841818.12 .. Rec_loss: 22999127.82 .. NELBO: 23871356.55\n",
      "****************************************************************************************************\n",
      "Epoch----->79 .. LR: 0.005 .. KL_theta: 28960.54 .. KL_eta: 404.29 .. KL_alpha: 842456.7 .. Rec_loss: 22814115.41 .. NELBO: 23685936.47\n",
      "****************************************************************************************************\n",
      "Epoch: 80 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27908.46 .. KL_eta: 393.09 .. KL_alpha: 833198.08 .. Rec_loss: 22512613.09 .. NELBO: 23374112.36\n",
      "****************************************************************************************************\n",
      "Epoch----->80 .. LR: 0.005 .. KL_theta: 27766.21 .. KL_eta: 392.64 .. KL_alpha: 830768.71 .. Rec_loss: 22721493.88 .. NELBO: 23580420.94\n",
      "****************************************************************************************************\n",
      "Epoch: 81 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28244.52 .. KL_eta: 462.03 .. KL_alpha: 817215.43 .. Rec_loss: 22752834.91 .. NELBO: 23598757.27\n",
      "****************************************************************************************************\n",
      "Epoch----->81 .. LR: 0.005 .. KL_theta: 27661.06 .. KL_eta: 445.41 .. KL_alpha: 817442.74 .. Rec_loss: 22705206.0 .. NELBO: 23550755.53\n",
      "****************************************************************************************************\n",
      "Epoch: 82 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27265.82 .. KL_eta: 355.73 .. KL_alpha: 806827.83 .. Rec_loss: 22399806.18 .. NELBO: 23234255.45\n",
      "****************************************************************************************************\n",
      "Epoch----->82 .. LR: 0.005 .. KL_theta: 27444.78 .. KL_eta: 342.1 .. KL_alpha: 808412.36 .. Rec_loss: 22536578.59 .. NELBO: 23372777.76\n",
      "****************************************************************************************************\n",
      "Epoch: 83 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29939.37 .. KL_eta: 412.65 .. KL_alpha: 801397.69 .. Rec_loss: 22618031.27 .. NELBO: 23449781.27\n",
      "****************************************************************************************************\n",
      "Epoch----->83 .. LR: 0.005 .. KL_theta: 29818.4 .. KL_eta: 401.67 .. KL_alpha: 799050.07 .. Rec_loss: 22426010.59 .. NELBO: 23255280.82\n",
      "****************************************************************************************************\n",
      "Epoch: 84 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27508.86 .. KL_eta: 331.86 .. KL_alpha: 793801.47 .. Rec_loss: 22442098.91 .. NELBO: 23263741.09\n",
      "****************************************************************************************************\n",
      "Epoch----->84 .. LR: 0.005 .. KL_theta: 27974.59 .. KL_eta: 357.42 .. KL_alpha: 788069.61 .. Rec_loss: 22527249.41 .. NELBO: 23343650.94\n",
      "****************************************************************************************************\n",
      "Epoch: 85 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27619.76 .. KL_eta: 417.82 .. KL_alpha: 778941.91 .. Rec_loss: 22059014.0 .. NELBO: 22865992.73\n",
      "****************************************************************************************************\n",
      "Epoch----->85 .. LR: 0.005 .. KL_theta: 27513.68 .. KL_eta: 419.39 .. KL_alpha: 779083.24 .. Rec_loss: 22305608.59 .. NELBO: 23112624.24\n",
      "****************************************************************************************************\n",
      "Epoch: 86 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29043.78 .. KL_eta: 442.89 .. KL_alpha: 766125.63 .. Rec_loss: 22495987.27 .. NELBO: 23291599.82\n",
      "****************************************************************************************************\n",
      "Epoch----->86 .. LR: 0.005 .. KL_theta: 28902.45 .. KL_eta: 441.04 .. KL_alpha: 764642.76 .. Rec_loss: 22204045.18 .. NELBO: 22998031.76\n",
      "****************************************************************************************************\n",
      "Epoch: 87 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28172.15 .. KL_eta: 431.58 .. KL_alpha: 762335.99 .. Rec_loss: 22354182.18 .. NELBO: 23145121.82\n",
      "****************************************************************************************************\n",
      "Epoch----->87 .. LR: 0.005 .. KL_theta: 27818.03 .. KL_eta: 441.43 .. KL_alpha: 761117.72 .. Rec_loss: 22146655.65 .. NELBO: 22936032.82\n",
      "****************************************************************************************************\n",
      "Epoch: 88 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27570.34 .. KL_eta: 466.71 .. KL_alpha: 752192.02 .. Rec_loss: 21659763.27 .. NELBO: 22439992.18\n",
      "****************************************************************************************************\n",
      "Epoch----->88 .. LR: 0.005 .. KL_theta: 27533.33 .. KL_eta: 444.66 .. KL_alpha: 750302.56 .. Rec_loss: 21887092.35 .. NELBO: 22665372.82\n",
      "****************************************************************************************************\n",
      "Epoch: 89 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29193.63 .. KL_eta: 426.44 .. KL_alpha: 740437.89 .. Rec_loss: 21874703.27 .. NELBO: 22644761.45\n",
      "****************************************************************************************************\n",
      "Epoch----->89 .. LR: 0.005 .. KL_theta: 29327.67 .. KL_eta: 459.51 .. KL_alpha: 738233.61 .. Rec_loss: 21852164.35 .. NELBO: 22620185.53\n",
      "****************************************************************************************************\n",
      "Epoch: 90 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28218.37 .. KL_eta: 597.31 .. KL_alpha: 730739.4 .. Rec_loss: 21787736.73 .. NELBO: 22547291.45\n",
      "****************************************************************************************************\n",
      "Epoch----->90 .. LR: 0.005 .. KL_theta: 28118.49 .. KL_eta: 576.05 .. KL_alpha: 729356.64 .. Rec_loss: 21784897.29 .. NELBO: 22542948.24\n",
      "****************************************************************************************************\n",
      "Epoch: 91 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27401.37 .. KL_eta: 450.99 .. KL_alpha: 724516.92 .. Rec_loss: 21827533.09 .. NELBO: 22579902.18\n",
      "****************************************************************************************************\n",
      "Epoch----->91 .. LR: 0.005 .. KL_theta: 27962.25 .. KL_eta: 458.92 .. KL_alpha: 722715.05 .. Rec_loss: 21837123.18 .. NELBO: 22588259.18\n",
      "****************************************************************************************************\n",
      "Epoch: 92 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28808.32 .. KL_eta: 487.7 .. KL_alpha: 717862.11 .. Rec_loss: 21842642.73 .. NELBO: 22589800.55\n",
      "****************************************************************************************************\n",
      "Epoch----->92 .. LR: 0.005 .. KL_theta: 29302.56 .. KL_eta: 507.25 .. KL_alpha: 715337.44 .. Rec_loss: 21743491.88 .. NELBO: 22488638.82\n",
      "****************************************************************************************************\n",
      "Epoch: 93 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30304.09 .. KL_eta: 455.2 .. KL_alpha: 707468.26 .. Rec_loss: 21715772.55 .. NELBO: 22453999.82\n",
      "****************************************************************************************************\n",
      "Epoch----->93 .. LR: 0.005 .. KL_theta: 29120.93 .. KL_eta: 414.42 .. KL_alpha: 707329.58 .. Rec_loss: 21800900.47 .. NELBO: 22537765.29\n",
      "****************************************************************************************************\n",
      "Epoch: 94 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28630.74 .. KL_eta: 520.91 .. KL_alpha: 700344.09 .. Rec_loss: 21587509.45 .. NELBO: 22317005.09\n",
      "****************************************************************************************************\n",
      "Epoch----->94 .. LR: 0.005 .. KL_theta: 29559.23 .. KL_eta: 559.37 .. KL_alpha: 699233.26 .. Rec_loss: 21468785.76 .. NELBO: 22198137.53\n",
      "****************************************************************************************************\n",
      "Epoch: 95 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28772.06 .. KL_eta: 543.96 .. KL_alpha: 687739.56 .. Rec_loss: 21444929.82 .. NELBO: 22161985.09\n",
      "****************************************************************************************************\n",
      "Epoch----->95 .. LR: 0.005 .. KL_theta: 28447.88 .. KL_eta: 529.27 .. KL_alpha: 687752.23 .. Rec_loss: 21455305.76 .. NELBO: 22172034.82\n",
      "****************************************************************************************************\n",
      "Epoch: 96 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30160.69 .. KL_eta: 469.16 .. KL_alpha: 680638.15 .. Rec_loss: 21696990.91 .. NELBO: 22408258.73\n",
      "****************************************************************************************************\n",
      "Epoch----->96 .. LR: 0.005 .. KL_theta: 30564.06 .. KL_eta: 449.57 .. KL_alpha: 679520.92 .. Rec_loss: 21444986.59 .. NELBO: 22155520.82\n",
      "****************************************************************************************************\n",
      "Epoch: 97 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28422.67 .. KL_eta: 434.05 .. KL_alpha: 674085.69 .. Rec_loss: 21412068.36 .. NELBO: 22115010.73\n",
      "****************************************************************************************************\n",
      "Epoch----->97 .. LR: 0.005 .. KL_theta: 28728.3 .. KL_eta: 440.71 .. KL_alpha: 672696.84 .. Rec_loss: 21465660.0 .. NELBO: 22167525.88\n",
      "****************************************************************************************************\n",
      "Epoch: 98 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28489.44 .. KL_eta: 373.14 .. KL_alpha: 661065.99 .. Rec_loss: 21505958.55 .. NELBO: 22195886.73\n",
      "****************************************************************************************************\n",
      "Epoch----->98 .. LR: 0.005 .. KL_theta: 28831.17 .. KL_eta: 375.39 .. KL_alpha: 660845.8 .. Rec_loss: 21347015.06 .. NELBO: 22037067.18\n",
      "****************************************************************************************************\n",
      "Epoch: 99 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29155.24 .. KL_eta: 533.42 .. KL_alpha: 657584.83 .. Rec_loss: 21385409.64 .. NELBO: 22072683.09\n",
      "****************************************************************************************************\n",
      "Epoch----->99 .. LR: 0.005 .. KL_theta: 28659.99 .. KL_eta: 576.01 .. KL_alpha: 655971.72 .. Rec_loss: 21318632.82 .. NELBO: 22003840.35\n",
      "****************************************************************************************************\n",
      "Epoch: 100 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28275.27 .. KL_eta: 537.33 .. KL_alpha: 650852.62 .. Rec_loss: 21338117.64 .. NELBO: 22017782.73\n",
      "****************************************************************************************************\n",
      "Epoch----->100 .. LR: 0.005 .. KL_theta: 27967.18 .. KL_eta: 498.0 .. KL_alpha: 649639.97 .. Rec_loss: 21199022.24 .. NELBO: 21877127.41\n",
      "****************************************************************************************************\n",
      "Epoch: 101 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 31414.14 .. KL_eta: 593.74 .. KL_alpha: 642196.62 .. Rec_loss: 21161711.27 .. NELBO: 21835915.64\n",
      "****************************************************************************************************\n",
      "Epoch----->101 .. LR: 0.005 .. KL_theta: 30490.15 .. KL_eta: 604.5 .. KL_alpha: 640736.88 .. Rec_loss: 21218398.94 .. NELBO: 21890230.35\n",
      "****************************************************************************************************\n",
      "Epoch: 102 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29255.63 .. KL_eta: 600.61 .. KL_alpha: 633202.14 .. Rec_loss: 21195145.82 .. NELBO: 21858204.0\n",
      "****************************************************************************************************\n",
      "Epoch----->102 .. LR: 0.005 .. KL_theta: 30564.0 .. KL_eta: 574.27 .. KL_alpha: 632180.03 .. Rec_loss: 21043308.82 .. NELBO: 21706627.06\n",
      "****************************************************************************************************\n",
      "Epoch: 103 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27965.25 .. KL_eta: 419.31 .. KL_alpha: 628198.01 .. Rec_loss: 20501537.27 .. NELBO: 21158119.82\n",
      "****************************************************************************************************\n",
      "Epoch----->103 .. LR: 0.005 .. KL_theta: 28038.3 .. KL_eta: 429.21 .. KL_alpha: 624900.28 .. Rec_loss: 21118465.53 .. NELBO: 21771833.18\n",
      "****************************************************************************************************\n",
      "Epoch: 104 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30260.44 .. KL_eta: 478.55 .. KL_alpha: 620844.3 .. Rec_loss: 21144817.82 .. NELBO: 21796400.91\n",
      "****************************************************************************************************\n",
      "Epoch----->104 .. LR: 0.005 .. KL_theta: 29951.9 .. KL_eta: 471.81 .. KL_alpha: 619945.18 .. Rec_loss: 21060707.29 .. NELBO: 21711076.0\n",
      "****************************************************************************************************\n",
      "Epoch: 105 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29004.65 .. KL_eta: 393.84 .. KL_alpha: 612898.09 .. Rec_loss: 20610026.55 .. NELBO: 21252322.55\n",
      "****************************************************************************************************\n",
      "Epoch----->105 .. LR: 0.005 .. KL_theta: 29688.73 .. KL_eta: 390.91 .. KL_alpha: 613156.43 .. Rec_loss: 20897105.53 .. NELBO: 21540341.18\n",
      "****************************************************************************************************\n",
      "Epoch: 106 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 32634.91 .. KL_eta: 494.34 .. KL_alpha: 610051.58 .. Rec_loss: 21039376.55 .. NELBO: 21682557.09\n",
      "****************************************************************************************************\n",
      "Epoch----->106 .. LR: 0.005 .. KL_theta: 30036.28 .. KL_eta: 480.84 .. KL_alpha: 607811.07 .. Rec_loss: 20747210.24 .. NELBO: 21385538.35\n",
      "****************************************************************************************************\n",
      "Epoch: 107 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27430.5 .. KL_eta: 619.42 .. KL_alpha: 604384.52 .. Rec_loss: 20537272.73 .. NELBO: 21169707.09\n",
      "****************************************************************************************************\n",
      "Epoch----->107 .. LR: 0.005 .. KL_theta: 28281.28 .. KL_eta: 638.96 .. KL_alpha: 602859.96 .. Rec_loss: 20578463.18 .. NELBO: 21210243.53\n",
      "****************************************************************************************************\n",
      "Epoch: 108 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30067.44 .. KL_eta: 648.37 .. KL_alpha: 599624.05 .. Rec_loss: 20566656.55 .. NELBO: 21196996.73\n",
      "****************************************************************************************************\n",
      "Epoch----->108 .. LR: 0.005 .. KL_theta: 30048.77 .. KL_eta: 625.35 .. KL_alpha: 598079.72 .. Rec_loss: 20662461.06 .. NELBO: 21291215.06\n",
      "****************************************************************************************************\n",
      "Epoch: 109 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29583.47 .. KL_eta: 532.38 .. KL_alpha: 589912.26 .. Rec_loss: 20631039.27 .. NELBO: 21251067.09\n",
      "****************************************************************************************************\n",
      "Epoch----->109 .. LR: 0.005 .. KL_theta: 28505.12 .. KL_eta: 515.71 .. KL_alpha: 589134.04 .. Rec_loss: 20650227.88 .. NELBO: 21268382.35\n",
      "****************************************************************************************************\n",
      "Epoch: 110 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26987.88 .. KL_eta: 488.51 .. KL_alpha: 584334.11 .. Rec_loss: 20708242.0 .. NELBO: 21320052.55\n",
      "****************************************************************************************************\n",
      "Epoch----->110 .. LR: 0.005 .. KL_theta: 28372.42 .. KL_eta: 511.64 .. KL_alpha: 583765.37 .. Rec_loss: 20425634.35 .. NELBO: 21038284.12\n",
      "****************************************************************************************************\n",
      "Epoch: 111 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29616.6 .. KL_eta: 533.97 .. KL_alpha: 580637.69 .. Rec_loss: 20724852.55 .. NELBO: 21335640.18\n",
      "****************************************************************************************************\n",
      "Epoch----->111 .. LR: 0.005 .. KL_theta: 29104.42 .. KL_eta: 520.77 .. KL_alpha: 579676.32 .. Rec_loss: 20415297.41 .. NELBO: 21024598.47\n",
      "****************************************************************************************************\n",
      "Epoch: 112 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30244.91 .. KL_eta: 531.23 .. KL_alpha: 570941.15 .. Rec_loss: 20327977.45 .. NELBO: 20929694.73\n",
      "****************************************************************************************************\n",
      "Epoch----->112 .. LR: 0.005 .. KL_theta: 29799.19 .. KL_eta: 520.82 .. KL_alpha: 570143.33 .. Rec_loss: 20256600.24 .. NELBO: 20857063.88\n",
      "****************************************************************************************************\n",
      "Epoch: 113 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29498.52 .. KL_eta: 494.56 .. KL_alpha: 566238.39 .. Rec_loss: 20543070.73 .. NELBO: 21139302.18\n",
      "****************************************************************************************************\n",
      "Epoch----->113 .. LR: 0.005 .. KL_theta: 28940.54 .. KL_eta: 488.9 .. KL_alpha: 564632.26 .. Rec_loss: 20420591.18 .. NELBO: 21014652.59\n",
      "****************************************************************************************************\n",
      "Epoch: 114 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29168.34 .. KL_eta: 453.38 .. KL_alpha: 559821.84 .. Rec_loss: 20163313.45 .. NELBO: 20752757.09\n",
      "****************************************************************************************************\n",
      "Epoch----->114 .. LR: 0.005 .. KL_theta: 28920.23 .. KL_eta: 453.09 .. KL_alpha: 560669.88 .. Rec_loss: 20420337.29 .. NELBO: 21010380.35\n",
      "****************************************************************************************************\n",
      "Epoch: 115 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29622.51 .. KL_eta: 487.23 .. KL_alpha: 552438.62 .. Rec_loss: 19876674.91 .. NELBO: 20459223.45\n",
      "****************************************************************************************************\n",
      "Epoch----->115 .. LR: 0.005 .. KL_theta: 30165.8 .. KL_eta: 485.6 .. KL_alpha: 551536.18 .. Rec_loss: 20222126.35 .. NELBO: 20804314.12\n",
      "****************************************************************************************************\n",
      "Epoch: 116 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27445.53 .. KL_eta: 502.67 .. KL_alpha: 548672.84 .. Rec_loss: 20439447.27 .. NELBO: 21016068.36\n",
      "****************************************************************************************************\n",
      "Epoch----->116 .. LR: 0.005 .. KL_theta: 28333.45 .. KL_eta: 556.77 .. KL_alpha: 548570.63 .. Rec_loss: 20218919.06 .. NELBO: 20796380.12\n",
      "****************************************************************************************************\n",
      "Epoch: 117 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28857.01 .. KL_eta: 660.66 .. KL_alpha: 541268.86 .. Rec_loss: 20019482.73 .. NELBO: 20590268.91\n",
      "****************************************************************************************************\n",
      "Epoch----->117 .. LR: 0.005 .. KL_theta: 29784.86 .. KL_eta: 680.3 .. KL_alpha: 541025.44 .. Rec_loss: 20136879.29 .. NELBO: 20708369.65\n",
      "****************************************************************************************************\n",
      "Epoch: 118 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28967.67 .. KL_eta: 664.52 .. KL_alpha: 537428.95 .. Rec_loss: 19794021.64 .. NELBO: 20361082.91\n",
      "****************************************************************************************************\n",
      "Epoch----->118 .. LR: 0.005 .. KL_theta: 29188.95 .. KL_eta: 664.73 .. KL_alpha: 536186.48 .. Rec_loss: 20014899.41 .. NELBO: 20580939.65\n",
      "****************************************************************************************************\n",
      "Epoch: 119 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28761.34 .. KL_eta: 630.22 .. KL_alpha: 533513.41 .. Rec_loss: 20050112.73 .. NELBO: 20613017.64\n",
      "****************************************************************************************************\n",
      "Epoch----->119 .. LR: 0.005 .. KL_theta: 29275.78 .. KL_eta: 629.34 .. KL_alpha: 534005.03 .. Rec_loss: 20115035.18 .. NELBO: 20678945.41\n",
      "****************************************************************************************************\n",
      "Epoch: 120 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27503.88 .. KL_eta: 545.09 .. KL_alpha: 527305.02 .. Rec_loss: 20095018.36 .. NELBO: 20650372.18\n",
      "****************************************************************************************************\n",
      "Epoch----->120 .. LR: 0.005 .. KL_theta: 27460.47 .. KL_eta: 601.55 .. KL_alpha: 525908.75 .. Rec_loss: 19991737.76 .. NELBO: 20545708.24\n",
      "****************************************************************************************************\n",
      "Epoch: 121 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28732.41 .. KL_eta: 1061.14 .. KL_alpha: 522819.54 .. Rec_loss: 19873218.0 .. NELBO: 20425831.27\n",
      "****************************************************************************************************\n",
      "Epoch----->121 .. LR: 0.005 .. KL_theta: 28919.5 .. KL_eta: 1039.83 .. KL_alpha: 521554.54 .. Rec_loss: 19890497.18 .. NELBO: 20442011.18\n",
      "****************************************************************************************************\n",
      "Epoch: 122 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30187.84 .. KL_eta: 991.02 .. KL_alpha: 519816.02 .. Rec_loss: 19788098.0 .. NELBO: 20339093.45\n",
      "****************************************************************************************************\n",
      "Epoch----->122 .. LR: 0.005 .. KL_theta: 29693.39 .. KL_eta: 906.87 .. KL_alpha: 518508.28 .. Rec_loss: 20016118.71 .. NELBO: 20565227.76\n",
      "****************************************************************************************************\n",
      "Epoch: 123 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29616.7 .. KL_eta: 743.45 .. KL_alpha: 512707.09 .. Rec_loss: 19593864.73 .. NELBO: 20136931.82\n",
      "****************************************************************************************************\n",
      "Epoch----->123 .. LR: 0.005 .. KL_theta: 29320.89 .. KL_eta: 727.9 .. KL_alpha: 512647.42 .. Rec_loss: 19831113.65 .. NELBO: 20373809.76\n",
      "****************************************************************************************************\n",
      "Epoch: 124 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29597.59 .. KL_eta: 758.24 .. KL_alpha: 511386.85 .. Rec_loss: 19626126.91 .. NELBO: 20167869.64\n",
      "****************************************************************************************************\n",
      "Epoch----->124 .. LR: 0.005 .. KL_theta: 29673.92 .. KL_eta: 692.17 .. KL_alpha: 508488.07 .. Rec_loss: 19846613.53 .. NELBO: 20385467.65\n",
      "****************************************************************************************************\n",
      "Epoch: 125 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28520.44 .. KL_eta: 532.53 .. KL_alpha: 506254.66 .. Rec_loss: 19812963.45 .. NELBO: 20348270.73\n",
      "****************************************************************************************************\n",
      "Epoch----->125 .. LR: 0.005 .. KL_theta: 28351.99 .. KL_eta: 558.63 .. KL_alpha: 505762.79 .. Rec_loss: 19663858.82 .. NELBO: 20198532.12\n",
      "****************************************************************************************************\n",
      "Epoch: 126 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28569.72 .. KL_eta: 654.23 .. KL_alpha: 499927.99 .. Rec_loss: 19640193.64 .. NELBO: 20169345.64\n",
      "****************************************************************************************************\n",
      "Epoch----->126 .. LR: 0.005 .. KL_theta: 29720.24 .. KL_eta: 651.96 .. KL_alpha: 500224.06 .. Rec_loss: 19609083.29 .. NELBO: 20139679.53\n",
      "****************************************************************************************************\n",
      "Epoch: 127 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30411.97 .. KL_eta: 614.15 .. KL_alpha: 496928.48 .. Rec_loss: 19385840.18 .. NELBO: 19913794.36\n",
      "****************************************************************************************************\n",
      "Epoch----->127 .. LR: 0.005 .. KL_theta: 29948.71 .. KL_eta: 622.99 .. KL_alpha: 495420.31 .. Rec_loss: 19648894.47 .. NELBO: 20174886.24\n",
      "****************************************************************************************************\n",
      "Epoch: 128 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 30346.42 .. KL_eta: 757.53 .. KL_alpha: 492547.43 .. Rec_loss: 19221325.09 .. NELBO: 19744976.73\n",
      "****************************************************************************************************\n",
      "Epoch----->128 .. LR: 0.005 .. KL_theta: 29627.72 .. KL_eta: 770.36 .. KL_alpha: 493382.44 .. Rec_loss: 19414554.82 .. NELBO: 19938335.41\n",
      "****************************************************************************************************\n",
      "Epoch: 129 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28551.05 .. KL_eta: 718.35 .. KL_alpha: 488064.65 .. Rec_loss: 19482045.55 .. NELBO: 19999379.45\n",
      "****************************************************************************************************\n",
      "Epoch----->129 .. LR: 0.005 .. KL_theta: 28785.49 .. KL_eta: 713.61 .. KL_alpha: 486306.54 .. Rec_loss: 19516719.12 .. NELBO: 20032524.82\n",
      "****************************************************************************************************\n",
      "Epoch: 130 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27570.22 .. KL_eta: 586.39 .. KL_alpha: 481190.95 .. Rec_loss: 19392897.45 .. NELBO: 19902245.09\n",
      "****************************************************************************************************\n",
      "Epoch----->130 .. LR: 0.005 .. KL_theta: 28644.98 .. KL_eta: 615.37 .. KL_alpha: 481076.26 .. Rec_loss: 19434808.82 .. NELBO: 19945145.29\n",
      "****************************************************************************************************\n",
      "Epoch: 131 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28886.41 .. KL_eta: 662.67 .. KL_alpha: 479997.83 .. Rec_loss: 19316992.0 .. NELBO: 19826539.09\n",
      "****************************************************************************************************\n",
      "Epoch----->131 .. LR: 0.005 .. KL_theta: 29183.85 .. KL_eta: 666.15 .. KL_alpha: 479959.31 .. Rec_loss: 19531121.06 .. NELBO: 20040930.47\n",
      "****************************************************************************************************\n",
      "Epoch: 132 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28171.05 .. KL_eta: 600.13 .. KL_alpha: 473466.72 .. Rec_loss: 19736036.55 .. NELBO: 20238273.64\n",
      "****************************************************************************************************\n",
      "Epoch----->132 .. LR: 0.005 .. KL_theta: 27988.45 .. KL_eta: 590.59 .. KL_alpha: 473758.06 .. Rec_loss: 19298368.82 .. NELBO: 19800705.29\n",
      "****************************************************************************************************\n",
      "Epoch: 133 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29876.75 .. KL_eta: 649.49 .. KL_alpha: 471090.01 .. Rec_loss: 19005773.27 .. NELBO: 19507389.45\n",
      "****************************************************************************************************\n",
      "Epoch----->133 .. LR: 0.005 .. KL_theta: 29099.6 .. KL_eta: 652.99 .. KL_alpha: 471306.44 .. Rec_loss: 19300694.12 .. NELBO: 19801753.06\n",
      "****************************************************************************************************\n",
      "Epoch: 134 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28516.58 .. KL_eta: 703.59 .. KL_alpha: 466689.99 .. Rec_loss: 19218306.36 .. NELBO: 19714216.55\n",
      "****************************************************************************************************\n",
      "Epoch----->134 .. LR: 0.005 .. KL_theta: 28665.28 .. KL_eta: 694.82 .. KL_alpha: 466317.61 .. Rec_loss: 19361170.47 .. NELBO: 19856848.47\n",
      "****************************************************************************************************\n",
      "Epoch: 135 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28632.79 .. KL_eta: 735.32 .. KL_alpha: 463704.64 .. Rec_loss: 19241407.18 .. NELBO: 19734479.45\n",
      "****************************************************************************************************\n",
      "Epoch----->135 .. LR: 0.005 .. KL_theta: 28784.99 .. KL_eta: 732.98 .. KL_alpha: 462302.93 .. Rec_loss: 19249691.71 .. NELBO: 19741512.35\n",
      "****************************************************************************************************\n",
      "Epoch: 136 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27515.56 .. KL_eta: 760.05 .. KL_alpha: 459476.18 .. Rec_loss: 19570885.27 .. NELBO: 20058637.45\n",
      "****************************************************************************************************\n",
      "Epoch----->136 .. LR: 0.005 .. KL_theta: 27218.61 .. KL_eta: 749.06 .. KL_alpha: 458693.94 .. Rec_loss: 19263584.12 .. NELBO: 19750245.88\n",
      "****************************************************************************************************\n",
      "Epoch: 137 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29742.94 .. KL_eta: 770.17 .. KL_alpha: 455849.77 .. Rec_loss: 18920744.36 .. NELBO: 19407106.91\n",
      "****************************************************************************************************\n",
      "Epoch----->137 .. LR: 0.005 .. KL_theta: 29161.9 .. KL_eta: 717.53 .. KL_alpha: 456180.6 .. Rec_loss: 19082503.76 .. NELBO: 19568563.41\n",
      "****************************************************************************************************\n",
      "Epoch: 138 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28570.83 .. KL_eta: 606.81 .. KL_alpha: 453962.12 .. Rec_loss: 19282566.36 .. NELBO: 19765705.82\n",
      "****************************************************************************************************\n",
      "Epoch----->138 .. LR: 0.005 .. KL_theta: 28636.62 .. KL_eta: 673.37 .. KL_alpha: 452345.58 .. Rec_loss: 19094693.06 .. NELBO: 19576348.47\n",
      "****************************************************************************************************\n",
      "Epoch: 139 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 28241.78 .. KL_eta: 859.29 .. KL_alpha: 448505.25 .. Rec_loss: 19218765.09 .. NELBO: 19696371.09\n",
      "****************************************************************************************************\n",
      "Epoch----->139 .. LR: 0.005 .. KL_theta: 28037.62 .. KL_eta: 846.82 .. KL_alpha: 448866.44 .. Rec_loss: 19074358.24 .. NELBO: 19552108.94\n",
      "****************************************************************************************************\n",
      "Epoch: 140 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29530.5 .. KL_eta: 753.87 .. KL_alpha: 444592.67 .. Rec_loss: 19303554.91 .. NELBO: 19778431.82\n",
      "****************************************************************************************************\n",
      "Epoch----->140 .. LR: 0.005 .. KL_theta: 29703.91 .. KL_eta: 791.12 .. KL_alpha: 443799.69 .. Rec_loss: 18929680.41 .. NELBO: 19403975.0\n",
      "****************************************************************************************************\n",
      "Epoch: 141 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27104.51 .. KL_eta: 779.19 .. KL_alpha: 441223.9 .. Rec_loss: 19194207.27 .. NELBO: 19663314.36\n",
      "****************************************************************************************************\n",
      "Epoch----->141 .. LR: 0.005 .. KL_theta: 27451.25 .. KL_eta: 815.97 .. KL_alpha: 441291.31 .. Rec_loss: 19018091.88 .. NELBO: 19487650.12\n",
      "****************************************************************************************************\n",
      "Epoch: 142 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27381.91 .. KL_eta: 810.81 .. KL_alpha: 437689.61 .. Rec_loss: 18962714.55 .. NELBO: 19428596.91\n",
      "****************************************************************************************************\n",
      "Epoch----->142 .. LR: 0.005 .. KL_theta: 27969.55 .. KL_eta: 792.81 .. KL_alpha: 437698.44 .. Rec_loss: 18953150.18 .. NELBO: 19419611.06\n",
      "****************************************************************************************************\n",
      "Epoch: 143 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 29531.02 .. KL_eta: 850.77 .. KL_alpha: 436911.49 .. Rec_loss: 19230899.27 .. NELBO: 19698192.0\n",
      "****************************************************************************************************\n",
      "Epoch----->143 .. LR: 0.005 .. KL_theta: 28243.25 .. KL_eta: 863.68 .. KL_alpha: 435608.75 .. Rec_loss: 18903610.41 .. NELBO: 19368325.53\n",
      "****************************************************************************************************\n",
      "Epoch: 144 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27816.91 .. KL_eta: 877.59 .. KL_alpha: 428660.05 .. Rec_loss: 18767078.0 .. NELBO: 19224433.09\n",
      "****************************************************************************************************\n",
      "Epoch----->144 .. LR: 0.005 .. KL_theta: 27215.84 .. KL_eta: 875.84 .. KL_alpha: 427612.81 .. Rec_loss: 19002738.0 .. NELBO: 19458442.71\n",
      "****************************************************************************************************\n",
      "Epoch: 145 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26467.09 .. KL_eta: 849.89 .. KL_alpha: 427291.51 .. Rec_loss: 19033527.82 .. NELBO: 19488136.0\n",
      "****************************************************************************************************\n",
      "Epoch----->145 .. LR: 0.005 .. KL_theta: 26307.36 .. KL_eta: 827.81 .. KL_alpha: 426279.89 .. Rec_loss: 18863535.06 .. NELBO: 19316950.0\n",
      "****************************************************************************************************\n",
      "Epoch: 146 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27001.75 .. KL_eta: 798.41 .. KL_alpha: 424819.33 .. Rec_loss: 18796615.82 .. NELBO: 19249235.09\n",
      "****************************************************************************************************\n",
      "Epoch----->146 .. LR: 0.005 .. KL_theta: 27286.6 .. KL_eta: 827.36 .. KL_alpha: 422983.48 .. Rec_loss: 18840486.59 .. NELBO: 19291584.12\n",
      "****************************************************************************************************\n",
      "Epoch: 147 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 25466.19 .. KL_eta: 859.0 .. KL_alpha: 420507.18 .. Rec_loss: 18697613.09 .. NELBO: 19144445.82\n",
      "****************************************************************************************************\n",
      "Epoch----->147 .. LR: 0.005 .. KL_theta: 25544.34 .. KL_eta: 863.51 .. KL_alpha: 419716.57 .. Rec_loss: 18871417.41 .. NELBO: 19317542.0\n",
      "****************************************************************************************************\n",
      "Epoch: 148 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 27450.57 .. KL_eta: 901.74 .. KL_alpha: 419177.32 .. Rec_loss: 19046576.91 .. NELBO: 19494106.36\n",
      "****************************************************************************************************\n",
      "Epoch----->148 .. LR: 0.005 .. KL_theta: 27396.1 .. KL_eta: 916.11 .. KL_alpha: 418165.13 .. Rec_loss: 18684615.18 .. NELBO: 19131092.35\n",
      "****************************************************************************************************\n",
      "Epoch: 149 .. batch: 10/17 .. LR: 0.005 .. KL_theta: 26575.53 .. KL_eta: 900.97 .. KL_alpha: 416119.91 .. Rec_loss: 18919150.36 .. NELBO: 19362746.55\n",
      "****************************************************************************************************\n",
      "Epoch----->149 .. LR: 0.005 .. KL_theta: 26034.89 .. KL_eta: 936.96 .. KL_alpha: 414087.62 .. Rec_loss: 18765290.59 .. NELBO: 19206349.76\n",
      "****************************************************************************************************\n",
      "saving topic matrix beta...\n",
      "CPU times: user 19h 42min 24s, sys: 48min 10s, total: 20h 30min 34s\n",
      "Wall time: 25min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train model on data by looping through multiple epochs\n",
    "best_epoch = 0\n",
    "best_val_ppl = 1e9\n",
    "all_val_ppls = []\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(\n",
    "        epoch,\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_tokens, \n",
    "        train_counts, \n",
    "        train_times, \n",
    "        train_rnn_inp,\n",
    "        args\n",
    "    )\n",
    "    ## check whether to anneal lr\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if args.anneal_lr and (len(all_val_ppls) > args.nonmono and val_ppl > min(all_val_ppls[:-args.nonmono]) and lr > 1e-5):\n",
    "        optimizer.param_groups[0]['lr'] /= args.lr_factor\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('saving topic matrix beta...')\n",
    "    alpha = model.mu_q_alpha\n",
    "    beta = model.get_beta(alpha).cpu().numpy()\n",
    "    scipy.io.savemat(ckpt+'_beta.mat', {'values': beta}, do_compression=True)\n",
    "    if args.train_embeddings:\n",
    "        print('saving word embedding matrix rho...')\n",
    "        rho = model.rho.weight.cpu().numpy()\n",
    "        scipy.io.savemat(ckpt+'_rho.mat', {'values': rho}, do_compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7661d-f62c-4e38-ae49-b37cd56e6121",
   "metadata": {},
   "source": [
    "## topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bd0334-017d-4249-b74d-04ecce12839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary([vocab])\n",
    "df = pd.read_parquet('data/combined_clean.parquet')\n",
    "split_text = df['filtered_text'].str.split().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72a5caa3-64aa-48c6-893e-2e50d23a1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:  torch.Size([10, 4, 4938])\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0 .. Time: 0 ===> ['bank', 'financial', 'banking', 'credit', 'asset', 'monetary', 'loan', 'fund', 'management']\n",
      "Topic 0 .. Time: 2 ===> ['interest', 'text', 'continue', 'paper', 'view', 'financial', 'important', 'need', 'note']\n",
      "Topic 1 .. Time: 0 ===> ['time', 'recent', 'change', 'growth', 'example', 'new', 'business', 'financial', 'need']\n",
      "Topic 1 .. Time: 2 ===> ['financial', 'system', 'risk', 'crisis', 'institution', 'new', 'hold', 'stress', 'large']\n",
      "Topic 2 .. Time: 0 ===> ['policy', 'monetary', 'action', 'rate', 'issue', 'reserve', 'financial', 'interest', 'fund']\n",
      "Topic 2 .. Time: 2 ===> ['important', 'will', 'example', 'include', 'financial', 'rate', 'take', 'significant', 'growth']\n",
      "Topic 3 .. Time: 0 ===> ['rate', 'inflation', 'growth', 'percent', 'economy', 'low', 'high', 'term', 'year']\n",
      "Topic 3 .. Time: 2 ===> ['policy', 'long', 'year', 'low', 'time', 'rate', 'change', 'term', 'economy']\n",
      "Topic 4 .. Time: 0 ===> ['risk', 'capital', 'price', 'high', 'cost', 'low', 'reduce', 'rate', 'demand']\n",
      "Topic 4 .. Time: 2 ===> ['text', 'expectation', 'price', 'regulation', 'effect', 'cost', 'requirement', 'risk', 'force']\n",
      "Topic 5 .. Time: 0 ===> ['year', 'price', 'increase', 'rise', 'low', 'growth', 'rate', 'high', 'economy']\n",
      "Topic 5 .. Time: 2 ===> ['percent', 'inflation', 'rate', 'price', 'economy', 'growth', 'interest', 'firm', 'consumer']\n",
      "Topic 6 .. Time: 0 ===> ['growth', 'increase', 'interest', 'will', 'financial', 'rate', 'inflation', 'current', 'change']\n",
      "Topic 6 .. Time: 2 ===> ['return', 'large', 'financial', 'firm', 'risk', 'small', 'community', 'bank', 'provide']\n",
      "Topic 7 .. Time: 0 ===> ['capital', 'business', 'financial', 'price', 'time', 'new', 'change', 'investment', 'early']\n",
      "Topic 7 .. Time: 2 ===> ['time', 'financial', 'policy', 'change', 'will', 'important', 'increase', 'take', 'effect']\n",
      "Topic 8 .. Time: 0 ===> ['financial', 'business', 'management', 'will', 'country', 'important', 'come', 'policy', 'way']\n",
      "Topic 8 .. Time: 2 ===> ['return', 'year', 'long', 'low', 'recent', 'rate', 'growth', 'term', 'last']\n",
      "Topic 9 .. Time: 0 ===> ['increase', 'cost', 'growth', 'recent', 'long', 'interest', 'view', 'current', 'low']\n",
      "Topic 9 .. Time: 2 ===> ['policy', 'monetary', 'rate', 'inflation', 'term', 'interest', 'economy', 'remain', 'fund']\n"
     ]
    }
   ],
   "source": [
    "args.num_words = 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    alpha = model.mu_q_alpha\n",
    "    beta = model.get_beta(alpha) \n",
    "    print('beta: ', beta.size())\n",
    "    print('\\n')\n",
    "    print('#'*100)\n",
    "    print('Visualize topics...')\n",
    "    times = [0, 2]\n",
    "    topics_words = []\n",
    "    for k in range(args.num_topics):\n",
    "        for t in times:\n",
    "            gamma = beta[k, t, :]\n",
    "            top_words = list(gamma.cpu().numpy().argsort()[-args.num_words+1:][::-1])\n",
    "            topic_words = [id2word[a] for a in top_words]\n",
    "            topics_words.append(' '.join(topic_words))\n",
    "            print('Topic {} .. Time: {} ===> {}'.format(k, t, topic_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "875cc2f5-a7c3-40d7-99fa-009615a681fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:46<00:00, 11.57s/it]\n"
     ]
    }
   ],
   "source": [
    "coherences = []\n",
    "for t in tqdm(range(args.num_times)):\n",
    "    coherences.append(\n",
    "        CoherenceModel(\n",
    "            topics=get_detm_topics(model=model, time=t, num_words=20, vocab=id2word, num_topics=args.num_topics), # use 20 words to standardize with DTM\n",
    "            texts=split_text, \n",
    "            dictionary=id2word, \n",
    "            coherence='c_v'\n",
    "        ).get_coherence()\n",
    "    )\n",
    "\n",
    "coherences = np.array(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22d03c1d-39b2-4e16-ad65-15821cef7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_diversity(topics):\n",
    "    all_words = set(np.concatenate(topics))\n",
    "    return len(all_words) / (len(topics[0]) * len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6974375b-7d95-4791-86df-38bff566cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 200.79it/s]\n"
     ]
    }
   ],
   "source": [
    "diversities = []\n",
    "for t in tqdm(range(args.num_times)):\n",
    "    diversities.append(\n",
    "        topic_diversity(topics=get_detm_topics(model=model, time=t, num_words=20, vocab=id2word, num_topics=args.num_topics))\n",
    "    )\n",
    "    \n",
    "diversities = np.array(diversities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f594329e-4180-456a-973e-274a8d7be83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1699976422907841, 0.011359057839255672)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualities = diversities * coherences\n",
    "qualities.mean(), qualities.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c54a78a9-adff-489c-8105-df1610c3ba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.32740801, 0.31958769, 0.32274133, 0.34633701]),\n",
       " array([0.5  , 0.49 , 0.535, 0.54 ]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherences, diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "938b798d-82c2-4eb9-811a-b80f465d2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    'detm_stats_glove.npz',\n",
    "    coherence=coherences,\n",
    "    diversity=diversities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d776a194-a778-4970-8a1c-648dd7b9c66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1424"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id['economy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e72fe1-6167-47ed-9263-0575a07d03c5",
   "metadata": {},
   "source": [
    "## topic evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4cf213-2e2c-44e3-b719-980b68600902",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = scipy.io.loadmat('results/glove_detm_un_K_10_Htheta_800_Optim_adam_Clip_0.0_ThetaAct_relu_Lr_0.005_Bsz_100_RhoSize_300_L_3_minDF_100_trainEmbeddings_0_beta.mat')['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "775ec712-bd2d-4daa-8878-cbf2f5a547d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be01e02-26ab-44b0-9de7-70380d97dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_probs(word, topic, beta):\n",
    "    word_id = id2word.token2id[word]\n",
    "    probs = []\n",
    "    for t in range(4):\n",
    "        gamma = beta[topic, t, :]\n",
    "        probs.append(gamma[word_id])\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe929a84-a923-4681-a9dc-7cbb3bfe36bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['bank', 'financial', 'banking', 'credit', 'asset', 'monetary', 'loan', 'fund', 'management', 'investment', 'mortgage', 'finance', 'committee', 'ensure', 'debt', 'transaction', 'liquidity', 'lending', 'equity']\n",
      "1 ['time', 'recent', 'change', 'growth', 'example', 'new', 'business', 'financial', 'need', 'significant', 'future', 'year', 'great', 'important', 'include', 'reason', 'job', 'large', 'will']\n",
      "2 ['policy', 'monetary', 'action', 'rate', 'issue', 'reserve', 'financial', 'interest', 'fund', 'asset', 'crisis', 'investment', 'decision', 'raise', 'management', 'risk', 'credit', 'bank', 'price']\n",
      "3 ['rate', 'inflation', 'growth', 'percent', 'economy', 'low', 'high', 'term', 'year', 'period', 'unemployment', 'past', 'long', 'policy', 'interest', 'increase', 'short', 'average', 'current']\n",
      "4 ['risk', 'capital', 'price', 'high', 'cost', 'low', 'reduce', 'rate', 'demand', 'investment', 'government', 'debt', 'higher', 'value', 'percent', 'increase', 'growth', 'inflation', 'exposure']\n",
      "5 ['year', 'price', 'increase', 'rise', 'low', 'growth', 'rate', 'high', 'economy', 'past', 'recent', 'time', 'end', 'demand', 'change', 'percent', 'current', 'last', 'higher']\n",
      "6 ['growth', 'increase', 'interest', 'will', 'financial', 'rate', 'inflation', 'current', 'change', 'risk', 'time', 'bank', 'income', 'important', 'system', 'one', 'need', 'make', 'good']\n",
      "7 ['capital', 'business', 'financial', 'price', 'time', 'new', 'change', 'investment', 'early', 'provide', 'growth', 'firm', 'technology', 'development', 'credit', 'take', 'industry', 'need', 'make']\n",
      "8 ['financial', 'business', 'management', 'will', 'country', 'important', 'come', 'policy', 'way', 'continue', 'good', 'capital', 'focus', 'asset', 'large', 'banking', 'system', 'investment', 'interest']\n",
      "9 ['increase', 'cost', 'growth', 'recent', 'long', 'interest', 'view', 'current', 'low', 'significant', 'value', 'rate', 'price', 'continue', 'future', 'range', 'effort', 'require', 'likely']\n"
     ]
    }
   ],
   "source": [
    "for k in range(args.num_topics):\n",
    "    gamma = beta[k, 0, :]\n",
    "    top_words = list(gamma.argsort()[-20+1:][::-1])\n",
    "    topic_words = [id2word[a] for a in top_words]\n",
    "    print(k, topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e8a1933-9a06-4300-a2a9-b5d65e2ecb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "1\n",
      "2\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "    probs = []\n",
    "    for k in range(10):\n",
    "        gamma = beta[k,t,:]\n",
    "        probs.append(gamma[id2word.token2id['foreclosure']])\n",
    "    print(np.argmax(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0934e7-880b-4434-b8f2-d2982ab709fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({\n",
    "    'credit': get_word_probs('credit', 0, beta),\n",
    "    'security': get_word_probs('security', 8, beta),\n",
    "    'foreclosure': get_word_probs('foreclosure', 7, beta),\n",
    "    'subprime': get_word_probs('subprime', 7, beta),\n",
    "    'labor': get_word_probs('labor', 9, beta),\n",
    "    'technology': get_word_probs('technology', 7, beta),\n",
    "    #'vol': get_word_probs('vol', 3, model),\n",
    "    'demand': get_word_probs('demand', 4, beta),\n",
    "    'regulation': get_word_probs('regulation', 4, beta),\n",
    "    'requirement': get_word_probs('requirement', 4, beta),\n",
    "    'inflation': get_word_probs('inflation', 3, beta),\n",
    "    'unemployment': get_word_probs('unemployment', 3, beta),\n",
    "    'stress': get_word_probs('stress', 1, beta),\n",
    "})\n",
    "\n",
    "plot_df.to_csv('glove_evolve.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda4df50-1a3d-4ab0-83fd-09c7cba2a3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit</th>\n",
       "      <th>security</th>\n",
       "      <th>foreclosure</th>\n",
       "      <th>subprime</th>\n",
       "      <th>labor</th>\n",
       "      <th>technology</th>\n",
       "      <th>demand</th>\n",
       "      <th>regulation</th>\n",
       "      <th>requirement</th>\n",
       "      <th>inflation</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>6.937785e-08</td>\n",
       "      <td>5.105341e-07</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.846482e-13</td>\n",
       "      <td>6.970997e-12</td>\n",
       "      <td>0.386578</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>8.391542e-06</td>\n",
       "      <td>1.762110e-05</td>\n",
       "      <td>0.005340</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>1.421601e-08</td>\n",
       "      <td>1.055798e-07</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>4.121818e-05</td>\n",
       "      <td>6.561859e-05</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>1.364912e-02</td>\n",
       "      <td>1.096065e-02</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.013721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>3.004296e-04</td>\n",
       "      <td>1.491934e-04</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>1.039362e-02</td>\n",
       "      <td>7.503133e-04</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.013455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     credit  security   foreclosure      subprime     labor  technology  \\\n",
       "0  0.004670  0.001684  6.937785e-08  5.105341e-07  0.002416    0.015236   \n",
       "1  0.013119  0.004237  8.391542e-06  1.762110e-05  0.005340    0.000431   \n",
       "2  0.002345  0.000816  4.121818e-05  6.561859e-05  0.008876    0.001302   \n",
       "3  0.003765  0.000721  3.004296e-04  1.491934e-04  0.000158    0.000522   \n",
       "\n",
       "     demand    regulation   requirement  inflation  unemployment    stress  \n",
       "0  0.000002  2.846482e-13  6.970997e-12   0.386578      0.000278  0.000181  \n",
       "1  0.000831  1.421601e-08  1.055798e-07   0.007673      0.000419  0.001158  \n",
       "2  0.007674  1.364912e-02  1.096065e-02   0.008292      0.004303  0.013721  \n",
       "3  0.002667  1.039362e-02  7.503133e-04   0.001354      0.000472  0.013455  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdb116-0b29-4b90-a81a-5ad2f593e8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
